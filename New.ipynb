{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('1', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(Word('José','q',['1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q_José_[1]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('1', 'r', encoding='utf-8') as f:\n",
    "    s = f.read()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc (word):\n",
    "    s = word.encode('utf-8')\n",
    "    s = s.decode('utf-8')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, s=[]):\n",
    "        if lemma == None: self.lemma = ''\n",
    "        else: self.lemma = enc(lemma)\n",
    "        self.lang = lang\n",
    "        self.s = s\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.s:\n",
    "            if isinstance(self.s[0],list):\n",
    "                w = '['+'_'.join(['-'.join(i) for i in self.s])+']'\n",
    "            else:\n",
    "                w = '['+'-'.join(self.s)+']'\n",
    "        else:\n",
    "            w = '-'\n",
    "        return str(self.lang)+'_'+str(self.lemma)+'_'+str(w)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and (self.s == other.s or other.s in self.s or self.s in other.s)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        if self.lang == other.lang:\n",
    "            if self.lemma == other.lemma:\n",
    "                s1 = set(self.s)\n",
    "                s2 = set(other.s)\n",
    "                if (not s1 - s2) and (s1&s2==s1) and (s2 - s1):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "    \n",
    "    def write(self, mode='mono'):\n",
    "        if mode == 'mono':\n",
    "            return self.lemma + '\\t' + '_'.join([str(i) for i in self.s])\n",
    "        elif mode == 'bi':\n",
    "            return self.lang + '\\t' +  self.lemma + '\\t' + '_'.join([str(i) for i in self.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_languages():\n",
    "    G = nx.Graph()\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix', '').split('-')\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "    d = G.degree()\n",
    "    d = sorted(d, key=d.get, reverse=True)\n",
    "    #print (d)\n",
    "    with open('languages','w',encoding='utf-8') as f:\n",
    "        f.write('\\t'.join(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%time all_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monodix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tags(list):\n",
    "    def __le__(self, other):\n",
    "        s1 = set(self)\n",
    "        s2 = set(other)\n",
    "        if not s1 - s2 and s1&s2==s1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        s1 = set(self)\n",
    "        s2 = set(other)\n",
    "        if (not s1 - s2) and (s1&s2==s1) and (s2 - s1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if set(self) == set(other):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '-'.join(self)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordDict(dict):\n",
    "    def lemma(self, lemma):\n",
    "        self.lemma = lemma\n",
    "        \n",
    "class FilteredDict(dict):\n",
    "    def set_lang(self, lang):\n",
    "        self.lang = lang\n",
    "    \n",
    "    def lemma(self, lemma):\n",
    "        return self[self.lang+'_'+lemma]\n",
    "        \n",
    "    def add(self, word):\n",
    "        lemma = word.lang+'_'+word.lemma\n",
    "        tags = Tags(word.s)\n",
    "        if lemma in self:\n",
    "            #pass\n",
    "            if tags in self[lemma]:\n",
    "                self[lemma][tags] += 1\n",
    "            else:\n",
    "                self[lemma][tags] = 1\n",
    "        else:\n",
    "            self[lemma] = WordDict()\n",
    "            self[lemma].lemma(lemma)\n",
    "            self[lemma][tags] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_language_dict(lang):\n",
    "    dictionary = FilteredDict()\n",
    "    dictionary.set_lang(lang)\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if lang in pair:\n",
    "                if lang == pair[0]: side = 'l'\n",
    "                else: side = 'r'\n",
    "                try:\n",
    "                    with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                        t = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))     \n",
    "                    for word in parse_one(t, side, lang):\n",
    "                        try:\n",
    "                            print (word)\n",
    "                            dictionary.add(word)\n",
    "                        except:\n",
    "                            print (word)\n",
    "                except:\n",
    "                    pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_word(word, lang):\n",
    "    s = word.findall('.//s')\n",
    "    s = [i.attrib['n'] for i in s]\n",
    "    if word.text: st = str(word.text)\n",
    "    else: st = ''\n",
    "    #st = st.encode('utf-8')\n",
    "    #st = st.decode('utf-8')\n",
    "    #print(st)\n",
    "    return Word(st, lang, s)\n",
    "\n",
    "def parse_one (tree, side, lang):\n",
    "    tree = tree.find('section')\n",
    "    #print (len(tree))\n",
    "    for e in tree:\n",
    "        p = e.find('p')\n",
    "        if p:\n",
    "            word = one_word(p.find(side), lang)\n",
    "            yield word\n",
    "        else:\n",
    "            i = e.find('i')\n",
    "            #print (i)\n",
    "            if i:\n",
    "                word = one_word(i, lang)\n",
    "                yield word\n",
    "            else:\n",
    "                pass\n",
    "            #print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shorten(word_dict):\n",
    "    short = []\n",
    "    for i in sorted(word_dict, key=lambda x: (word_dict[x], -len(x)), reverse=True):\n",
    "        t = True\n",
    "        for key, j in enumerate(short):\n",
    "            if (j[0] < i) or (i < j[0]):\n",
    "                short[key].append(i)\n",
    "                t = False\n",
    "                break\n",
    "        if t:\n",
    "            short.append([i])\n",
    "    return word_dict.lemma[4:], short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dictionary_to_nodes(dictionary):\n",
    "    with open ('1', 'w', encoding = 'utf-8') as f:\n",
    "        for i in dictionary.keys():\n",
    "            word, tags = shorten(dictionary[i])\n",
    "            f.write(word+'\\n')\n",
    "            #print (word)\n",
    "            if '_' in word:\n",
    "                word = word.replace('_', ' ')\n",
    "            for tag in tags:\n",
    "                f.write(str(Word(word,'1',['']))+'\\n')\n",
    "                f.write(str(Word(word, dictionary.lang, Tags([i for i in tag if i])))+'\\n')\n",
    "                yield Word(word, dictionary.lang, Tags([i for i in tag if i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def monodix():\n",
    "    if not os.path.exists('./monodix/'):\n",
    "        os.makedirs('./monodix/')\n",
    "    with open('languages','r', encoding='utf-8') as f:\n",
    "        langs = f.read().split('\\t')[:2]\n",
    "    for lang in langs:\n",
    "        #print (lang, end = '\\t')\n",
    "        dictionary = one_language_dict(lang)\n",
    "        #with open ('1', 'w', encoding = 'utf-8') as f:\n",
    "        #    for i in dictionary:\n",
    "        #        f.write(i+'\\n')\n",
    "        with open ('./monodix/'+lang+'.dix', 'w', encoding = 'utf-8') as f:\n",
    "            for i in dictionary_to_nodes(dictionary):\n",
    "                f.write (i.write(mode='mono')+'\\n')\n",
    "        logging.info(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_0_[num]\n",
      "eng_1_[num]\n",
      "eng_2_[num]\n",
      "eng_3_[num]\n",
      "eng_4_[num]\n",
      "eng_5_[num]\n",
      "eng_6_[num]\n",
      "eng_7_[num]\n",
      "eng_8_[num]\n",
      "eng_9_[num]\n",
      "eng_600_[num]\n",
      "eng_42_[num]\n",
      "eng_._[sep]\n",
      "eng_\\_[sep]\n",
      "eng_?_[sep]\n",
      "eng_;_[sep]\n",
      "eng_:_[sep]\n",
      "eng_!_[sep]\n",
      "eng_।_[sep]\n",
      "eng_the_[det]\n",
      "eng_the_[det]\n",
      "eng_the_[det]\n",
      "eng_the_[det]\n",
      "eng_the_[det]\n",
      "eng_Rogers_[np-cog-pl]\n",
      "eng_Rojo_[np-cog-sg]\n",
      "eng_Rojo_[np-cog-pl]\n",
      "eng_Román_[np-ant]\n"
     ]
    }
   ],
   "source": [
    "%time monodix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'n'.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_mono(lang):\n",
    "    dictionary = []\n",
    "    with open ('./monodix/{}.dix'.format(lang), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            string = line.split('\\t')\n",
    "            dictionary.append(Word(string[0], lang, [Tags(i.split('-')) for i in string[1].strip().split('_')]))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_word(word, lang):\n",
    "    s = word.findall('.//s')\n",
    "    s = [i.attrib['n'] for i in s]\n",
    "    if word.text: st = str(word.text)\n",
    "    else: st = ''\n",
    "    st = st.encode('utf-8')\n",
    "    st = st.decode('utf-8')\n",
    "    #print(st)\n",
    "    return Word(st, lang, s)\n",
    "\n",
    "def parse_bidix (tree, l1, l2):\n",
    "    tree = tree.find('section')\n",
    "    if not tree:\n",
    "        pass\n",
    "        #print (l1, l2)\n",
    "    else:\n",
    "        for e in tree:\n",
    "            if 'n' in e.attrib:\n",
    "                side = e.attrib['n']\n",
    "            else:\n",
    "                side = ''\n",
    "            p = e.find('p')\n",
    "            if p:\n",
    "                yield one_word(p.find('l'), l1), one_word(p.find('r'), l2), side\n",
    "            else:\n",
    "                i = e.find('i')\n",
    "                if i:\n",
    "                    yield one_word(i, l1), one_word(i, l2), side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check (word1, word2, lang1, lang2):\n",
    "    word1 = lang1[lang1.index(word1)]\n",
    "    word2 = lang2[lang2.index(word2)]\n",
    "    return word1, word2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def existance(pair, nodes):\n",
    "    if pair[0] in nodes and pair[1] in nodes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_file(l1, l2):\n",
    "    with open ('language_list.csv','r',encoding='utf-8') as f:\n",
    "        languages = set([i.split('\\t')[1].strip() for i in f.readlines()])\n",
    "    with open ('{}-{}'.format(l1, l2), 'w', encoding='utf-8') as f:\n",
    "        for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "            for fl in files:\n",
    "                #print (fl)\n",
    "                pair = fl.replace('.dix','').split('-')\n",
    "                #print(pair)\n",
    "                if existance(pair, languages):\n",
    "                    logging.info('{}-{} started'.format(pair[0], pair[1]))\n",
    "                    lang1 = import_mono(pair[0])\n",
    "                    lang2 = import_mono(pair[1])\n",
    "                    with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                        try:\n",
    "                            tree = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))\n",
    "                            for word1, word2, side in parse_bidix (tree, pair[0], pair[1]):\n",
    "                                try:\n",
    "                                    word1, word2 = check (word1, word2, lang1, lang2)\n",
    "                                    string = str(side) + '\\t' + word1.write(mode='bi') + '\\t' + word2.write(mode='bi') + '\\n'\n",
    "                                    f.write(string)\n",
    "                                except:\n",
    "                                    print ('\\t', word1, word2)\n",
    "                        except IndexError:\n",
    "                            print ('ERROR: {}-{}'.format(pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time load_file('rus', 'fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [Word('f','f',[Tags(['n','adj']),Tags(['v'])])]\n",
    "Word('f','f',['v']) in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(1, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (isinstance(Word(1,1,Tags(['n','adj'])).lemma, str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fef69a54e1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<b/>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<.?g>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_bidix\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m#print (word1, word2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\t'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bi'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\t'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bi'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-2e460531cc1a>\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(word1, word2, lang1, lang2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mword1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlang1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlang1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mword2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlang2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlang2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-bd2bcd2ced0e>\u001b[0m in \u001b[0;36m__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pair = ['eng', 'deu']\n",
    "lang1 = import_mono(pair[0])\n",
    "lang2 = import_mono(pair[1])\n",
    "with open ('./dictionaries/eng-deu.dix', 'r', encoding='utf-8') as d:\n",
    "    tree = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))\n",
    "    for word1, word2, side in parse_bidix (tree, pair[0], pair[1]):\n",
    "        word1, word2 = check (word1, word2, lang1, lang2)\n",
    "        #print (word1, word2)\n",
    "        string = str(side) + '\\t' + word1.write(mode='bi') + '\\t' + word2.write(mode='bi') + '\\n'\n",
    "        #print (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word ('José','eng',['np']) in lang1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%time lang1 = import_mono('bel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1[0] in lang1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = Word('а', 'bel', ['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word in lang1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'а'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lang1[0].lemma = str(lang1[0].lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1[1].lemma == 'аазіс'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'а'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1[0].lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а ﻿а\n"
     ]
    }
   ],
   "source": [
    "print (word.lemma, lang1[0].lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Tags"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lang1[0].s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"аб'яктыў\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1[10].lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang1[0].s == word.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bel'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n] ['n']\n"
     ]
    }
   ],
   "source": [
    "print (lang1[0].lemma, word.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lang1[0].s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'а'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-0df2c3d6465c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlang1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# == word.lemma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "lang1[0].lemma.decode('utf-8')# == word.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('а', 'bel', Tags(['n'])) in lang1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
