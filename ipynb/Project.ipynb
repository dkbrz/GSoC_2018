{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilingual dictionary enrichment via graph completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "import pandas as pd\n",
    "lang_codes = pd.read_csv('./files/language-codes-full_csv.csv', na_values = nan, sep='\\t', header=0)\n",
    "lang_codes = lang_codes[['3','2']]\n",
    "lang_codes = lang_codes.dropna()\n",
    "\n",
    "\n",
    "lang_codes = [{i[0]:i[1] for i in np.array(lang_codes)}, {i[1]:i[0] for i in np.array(lang_codes)}]\n",
    "\n",
    "with open ('./files/lang_codes.json', 'w') as f:\n",
    "    json.dump(lang_codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fra'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('./files/lang_codes.json', 'r') as f:\n",
    "    lang_codes = json.load(f)\n",
    "\n",
    "def l(lang, mode=3):\n",
    "    mode = mode % 2\n",
    "    if len(lang)==2:\n",
    "        if lang in lang_codes[mode]:\n",
    "            return lang_codes[mode][lang]\n",
    "        else:\n",
    "            return lang\n",
    "    else:\n",
    "        return lang\n",
    "l('fr', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load user with login and password from secret file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "with open ('secure.json') as f:\n",
    "    SECRET = json.loads(f.read())\n",
    "\n",
    "github = Github(SECRET['USER'], SECRET['PASSWORD'])\n",
    "\n",
    "user = github.get_user('apertium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user.get_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generator ** : yield all repos that match name pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repo_names(user):\n",
    "    for repo in user.get_repos():\n",
    "        if re.match('apertium-[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?', repo.name):\n",
    "            yield repo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like heavy function. But I don't see any improvements yet, except for having certain repo for all bidix copies. But this one above is the most up-to-date. It filters not languages pair repos, it is needed not to look for bidix where it can't be. Function saves a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%time w = list(repo_names(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find bidix **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length sorting to reduce number of files to check (bidix is lone of the longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    for i in sorted(repo.get_dir_contents('/'), key = lambda x: (len(x.path), 1000-ord(('   '+x.path)[-3])), reverse=True):\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix$', i.path):\n",
    "            return i.download_url\n",
    "        elif len(i.path) < 23:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 709 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/apertium/apertium-cat-srd/master/apertium-cat-srd.cat-srd.dix'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bidix_url(github.get_repo(user.name+'/'+w[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Only relevant for certain language pair **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **164 ** pairs at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_all_bidixes(user):\n",
    "    logging.info('Start')\n",
    "    if not os.path.exists('./dictionaries/'):\n",
    "        os.makedirs('./dictionaries/')\n",
    "    for repo_name in repo_names(user):\n",
    "        bidix = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        langs = [l(i) for i in repo_name.split('-')[1:]]\n",
    "        filename = './dictionaries/'+'-'.join(langs)+'.dix'\n",
    "        if bidix:\n",
    "            response = requests.get(bidix)\n",
    "            response.encoding = 'UTF-8'\n",
    "            with open(filename, 'w', encoding='UTF-8') as f:\n",
    "                f.write(response.text)\n",
    "    logging.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-22 15:26:56,733 | INFO : Start\n",
      "2018-05-22 15:44:22,590 | INFO : Finish\n"
     ]
    }
   ],
   "source": [
    "download_all_bidixes(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_languages(l1, l2):\n",
    "    G = nx.Graph()\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix', '').split('-')\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "    pair = [l(l1), l(l2)]\n",
    "    with open('language_list.csv','w', encoding='utf-8') as f:\n",
    "        nodes = set()\n",
    "        for i in range(1,5):\n",
    "            w = nx.single_source_shortest_path_length(G, pair[0], cutoff=i)\n",
    "            v = nx.single_source_shortest_path_length(G, pair[1], cutoff=i)\n",
    "            H = G.subgraph(w.keys())\n",
    "            H.remove_node(pair[0])\n",
    "            H2 = G.subgraph(v.keys())\n",
    "            H2.remove_node(pair[1])\n",
    "            if pair[1] in H.nodes():\n",
    "                v = nx.node_connected_component(H, pair[1])\n",
    "            else:\n",
    "                v = set()\n",
    "            if pair[0] in H2.nodes():\n",
    "                w = nx.node_connected_component(H, pair[1])\n",
    "            else:\n",
    "                w = set() \n",
    "            nodes2 = v & w | set([pair[0], pair[1]])\n",
    "            nodes2 = nodes2 - nodes\n",
    "            for node in nodes2:\n",
    "                f.write('{}\\t{}\\n'.format(i*2, node))\n",
    "            nodes = nodes | nodes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_languages('bel', 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_languages():\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files:\n",
    "            #print (root+fl)\n",
    "            try:\n",
    "                s = ET.parse(root+fl)\n",
    "            except:\n",
    "                print ('ERROR :'+fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR :epo-bul.dix\n",
      "ERROR :epo-per.dix\n",
      "ERROR :epo-pol.dix\n",
      "ERROR :fin-fra.dix\n",
      "ERROR :pol-lav.dix\n",
      "ERROR :sah-eng.dix\n"
     ]
    }
   ],
   "source": [
    "check_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def existance(pair, nodes):\n",
    "    if pair[0] in nodes and pair[1] in nodes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_chosen():\n",
    "    with open ('language_list.csv','r',encoding='utf-8') as f:\n",
    "        languages = set([i.split('\\t')[1].strip() for i in f.readlines()])\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files:\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if existance(pair, languages):\n",
    "                try:\n",
    "                    with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                        dictionary = d.read().replace('<b/>',' ').replace('<.?g>','')\n",
    "                        yield ET.fromstring(dictionary), pair[0], pair[1]\n",
    "                except:\n",
    "                    print ('ERROR: ', fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-per.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time len(list(load_chosen()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Word **\n",
    "\n",
    "- lemma : lemma\n",
    "- lang : language\n",
    "- pos : part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, s=[]):\n",
    "        self.lemma = lemma\n",
    "        self.lang = lang\n",
    "        self.s = s\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.lang)+'_'+str(self.lemma)+'_'+str('-'.join(self.s))\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and self.s == other.s\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidix parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 921 ms\n"
     ]
    }
   ],
   "source": [
    "%time T = tree('https://raw.githubusercontent.com/apertium/apertium-eng-ita/master/apertium-eng-ita.eng-ita.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_word(word, lang):\n",
    "    s = word.findall('.//s')\n",
    "    s = [i.attrib['n'] for i in s]\n",
    "    return Word(word.text, lang, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bidix (tree, l1, l2):\n",
    "    tree = tree.find('section')\n",
    "    if not tree:\n",
    "        pass\n",
    "        #print (l1, l2)\n",
    "    else:\n",
    "        for e in tree:\n",
    "            if 'n' in e.attrib:\n",
    "                side = e.attrib['n']\n",
    "            else:\n",
    "                side = None\n",
    "            p = e.find('p')\n",
    "            if p:\n",
    "                yield one_word(p.find('l'), l1), one_word(p.find('r'), l2), side\n",
    "            else:\n",
    "                i = e.find('i')\n",
    "                if i:\n",
    "                    yield one_word(i, l1), one_word(i, l2), side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 882 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48880"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% time len(list(parse_bidix (T, 'bel','rus')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bidix(G, T, l1, l2):\n",
    "    for word1, word2, side in parse_bidix (T, l1, l2):\n",
    "        if side == None:\n",
    "            G.add_edge(word1, word2)\n",
    "            G.add_edge(word2, word1)\n",
    "        elif side == 'LR':\n",
    "            G.add_edge(word1, word2)\n",
    "        elif side == 'RL':\n",
    "            G.add_edgr(word2, word1)\n",
    "        else:\n",
    "            print (side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetWithFilter(set):\n",
    "    def lemma(self, value):\n",
    "        return set(i for i in self if i.lemma == value)\n",
    "    def lang(self, value):\n",
    "        return set(i for i in self if i.lang == value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictionaries(G, l1,l2):\n",
    "    l1 = l(l1)\n",
    "    l2 = l(l2)\n",
    "    d_l1 = SetWithFilter()\n",
    "    d_l2 = SetWithFilter()\n",
    "    for i in G.nodes():\n",
    "        if i.lang == l1:\n",
    "            d_l1.add(i)\n",
    "        elif i.lang == l2:\n",
    "            d_l2.add(i)\n",
    "    return d_l1, d_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma_search (G, lemma, d_l1, l2, cutoff):\n",
    "    lemmas = d_l1.lemma(lemma)\n",
    "    print (G.degree(lemmas))\n",
    "    print (lemmas)\n",
    "    results = {str(word):{} for word in lemmas}\n",
    "    for word in lemmas:\n",
    "        print(word, end='\\t')\n",
    "        s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "        print ('all: ', str(len(s)), end='\\t')\n",
    "        s = s.lang(l2)\n",
    "        print ('filtered: ', str(len(s)))\n",
    "        for translation in s:\n",
    "            t = list(nx.all_simple_paths(G, word, translation, cutoff=cutoff))\n",
    "            t = [len(i) for i in t]\n",
    "            t = Counter(t)\n",
    "            coef = 0\n",
    "            for i in t:\n",
    "                coef += exp(-t[i])\n",
    "            results[str(word)][str(translation)] = coef\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for i in results:\n",
    "        print ('\\n\\t\\t', i)\n",
    "        for j in sorted(results[i], key=results[i].get, reverse=True)[:7]:\n",
    "            print (j, results[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUS-FRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_languages('rus', 'fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-22 21:46:47,006 | INFO : Start\n",
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-fas.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "lit lav\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "2018-05-22 21:52:49,343 | INFO : Finish\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "logging.info('Start')\n",
    "for T, l1, l2 in load_chosen():\n",
    "    add_bidix(G, T, l1, l2)\n",
    "logging.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('graph.pkl','wb') as f:\n",
    "    pkl.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('graph.pkl','rb') as f:\n",
    "    G = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l1, d_l2 = dictionaries(G, 'rus','fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_lemma (G, lemma, d_l1, l2):\n",
    "    lemmas = d_l1.lemma(lemma)\n",
    "    print (lemmas)\n",
    "    results = {str(word):{} for word in lemmas}\n",
    "    for word in lemmas:\n",
    "        print (word)\n",
    "        for cutoff in range(1, 8):\n",
    "            print (cutoff, end='\\t')\n",
    "            s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "            print ('all: ', str(len(s)), end='\\t')\n",
    "            s = s.lang(l2)\n",
    "            print ('filtered: ', str(len(s)))\n",
    "            if len(s)>150:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rus_собака_n-f-aa: 22, rus_собака_n-f: 2, rus_собака_n: 6}\n",
      "{rus_собака_n-f-aa, rus_собака_n-f, rus_собака_n}\n",
      "rus_собака_n-f-aa\tall:  2883\tfiltered:  37\n",
      "rus_собака_n-f\tall:  239\tfiltered:  3\n",
      "rus_собака_n\tall:  571\tfiltered:  15\n",
      "\n",
      "\t\t rus_собака_n-f-aa\n",
      "fra_chien_n-GD 0.4180019721672088\n",
      "fra_chien_n 0.36821490379934485\n",
      "fra_chien_n-m 0.3679248411012048\n",
      "fra_docteur_n 0.36787944117144233\n",
      "fra_docteur_n-GD 0.36787944117144233\n",
      "fra_sport_n-m 0.36787944117144233\n",
      "fra_compagnon_n 0.36787944117144233\n",
      "\n",
      "\t\t rus_собака_n-f\n",
      "fra_chien_n-GD 0.503214724408055\n",
      "fra_chien_n 0.36879132313699686\n",
      "fra_chien_n-m 0.36787944117144233\n",
      "\n",
      "\t\t rus_собака_n\n",
      "fra_chien_n-m 0.503214724408055\n",
      "fra_chien_n 0.41767265375165963\n",
      "fra_colimaçon_n-m 0.4176665095393063\n",
      "fra_limaçon_n-m 0.4176665095393063\n",
      "fra_chien_n-GD 0.4176665095393063\n",
      "fra_arobace_n-f 0.36787944117144233\n",
      "fra_but_n-m 0.36787944117144233\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'собака', d_l1, 'fra', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rus_поле_n: 6, rus_поле_n-nt: 2, rus_поле_n-nt-nn-pl: 2, rus_поле_n-nt-nn: 26}\n",
      "{rus_поле_n, rus_поле_n-nt, rus_поле_n-nt-nn-pl, rus_поле_n-nt-nn}\n",
      "rus_поле_n\tall:  278\tfiltered:  7\n",
      "rus_поле_n-nt\tall:  144\tfiltered:  2\n",
      "rus_поле_n-nt-nn-pl\tall:  3\tfiltered:  0\n",
      "rus_поле_n-nt-nn\tall:  1504\tfiltered:  11\n",
      "\n",
      "\t\t rus_поле_n\n",
      "fra_camp_n-m 0.7357588823428847\n",
      "fra_champ_n-m 0.7357588823428847\n",
      "fra_marge_n-m 0.7357588823428847\n",
      "fra_plantation_n-f 0.7357588823428847\n",
      "fra_marge_n-f 0.36787944117144233\n",
      "fra_rive_n-f 0.049787068367863944\n",
      "fra_berge_n-f 0.049787068367863944\n",
      "\n",
      "\t\t rus_поле_n-nt\n",
      "fra_camp_n-m 0.36787944117144233\n",
      "fra_champ_n-m 0.36787944117144233\n",
      "\n",
      "\t\t rus_поле_n-nt-nn-pl\n",
      "\n",
      "\t\t rus_поле_n-nt-nn\n",
      "fra_camp_n-m 0.3746173881705278\n",
      "fra_champ_n-m 0.3746173881705278\n",
      "fra_cadre_n 0.36787944117144233\n",
      "fra_camp_n 0.36787944117144233\n",
      "fra_patinoire_n-f 0.36787944117144233\n",
      "fra_champ_n 0.36787944117144233\n",
      "fra_domaine_n-m 0.36787944117144233\n",
      "Wall time: 689 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'поле', d_l1, 'fra', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{fra_serpent_n-m: 18, fra_serpent_n: 4, fra_serpent_n-m-ND: 2}\n",
      "{fra_serpent_n-m, fra_serpent_n, fra_serpent_n-m-ND}\n",
      "fra_serpent_n-m\tall:  725\tfiltered:  14\n",
      "fra_serpent_n\tall:  3\tfiltered:  0\n",
      "fra_serpent_n-m-ND\tall:  3\tfiltered:  0\n",
      "\n",
      "\t\t fra_serpent_n-m\n",
      "rus_змея_n 0.41768321124009655\n",
      "rus_змей_n 0.41768321124009655\n",
      "rus_змейка_n-f-nn 0.3861950800601765\n",
      "rus_змея_n-f-aa 0.3746173889287838\n",
      "rus_уж_n 0.3746173881705278\n",
      "rus_змей_n-m-aa 0.36879132313699686\n",
      "rus_гадюка_n-f-aa 0.36787944117144233\n",
      "\n",
      "\t\t fra_serpent_n\n",
      "\n",
      "\t\t fra_serpent_n-m-ND\n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'serpent', d_l2, 'rus', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{fra_enfant_n-m: 10, fra_enfant_n: 8, fra_enfant_n-n: 2, fra_enfant_n-mf-pl: 8, fra_enfant_n-m-ND: 2, fra_enfant_n-mf: 30, fra_enfant_n-mf-ND: 4, fra_enfant_n-mf-sg: 2}\n",
      "{fra_enfant_n-m, fra_enfant_n, fra_enfant_n-n, fra_enfant_n-mf-pl, fra_enfant_n-m-ND, fra_enfant_n-mf, fra_enfant_n-mf-ND, fra_enfant_n-mf-sg}\n",
      "fra_enfant_n-m\tall:  852\tfiltered:  19\n",
      "fra_enfant_n\tall:  782\tfiltered:  38\n",
      "fra_enfant_n-n\tall:  833\tfiltered:  17\n",
      "fra_enfant_n-mf-pl\tall:  45\tfiltered:  0\n",
      "fra_enfant_n-m-ND\tall:  32\tfiltered:  0\n",
      "fra_enfant_n-mf\tall:  6576\tfiltered:  88\n",
      "fra_enfant_n-mf-ND\tall:  586\tfiltered:  8\n",
      "fra_enfant_n-mf-sg\tall:  8\tfiltered:  0\n",
      "\n",
      "\t\t fra_enfant_n-m\n",
      "rus_мальчик_n-m-aa 0.3746173881705278\n",
      "rus_девочка_n-f-aa 0.3746173881705278\n",
      "rus_мадемуазель_n 0.36787944117144233\n",
      "rus_барышня_n 0.36787944117144233\n",
      "rus_паренек_n-m-aa 0.36787944117144233\n",
      "rus_сын_n-m-aa 0.36787944117144233\n",
      "rus_ребёнок_n 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n\n",
      "rus_мальчик_n 0.7357588823428847\n",
      "rus_ребенок_n-m-aa 0.503214724408055\n",
      "rus_младенец_n-m-aa 0.36821490379934485\n",
      "rus_чадо_n 0.36787944117144233\n",
      "rus_зрачок_n 0.36787944117144233\n",
      "rus_побочный сын_n 0.36787944117144233\n",
      "rus_малыш_n 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n-n\n",
      "rus_девочка_n-f-aa 0.4176665095393063\n",
      "rus_мальчик_n-m-aa 0.36879132313699686\n",
      "rus_мадемуазель_n 0.36787944117144233\n",
      "rus_барышня_n 0.36787944117144233\n",
      "rus_паренек_n-m-aa 0.36787944117144233\n",
      "rus_сын_n-m-aa 0.36787944117144233\n",
      "rus_юноша_n-m-aa 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n-mf-pl\n",
      "\n",
      "\t\t fra_enfant_n-m-ND\n",
      "\n",
      "\t\t fra_enfant_n-mf\n",
      "rus_барышня_n 0.503214724408055\n",
      "rus_незамужняя девица_n 0.503214724408055\n",
      "rus_мадемуазель_n 0.503214724408055\n",
      "rus_козленок_n-m-aa 0.503214724408055\n",
      "rus_грудной ребёнок_n 0.4176665095393063\n",
      "rus_ребёнок_n 0.38621178176096677\n",
      "rus_девка_n-f-aa 0.3861950800601765\n",
      "\n",
      "\t\t fra_enfant_n-mf-ND\n",
      "rus_ребёнок_n 0.1353352832366127\n",
      "rus_мальчик_n-m-aa 0.1353352832366127\n",
      "rus_девочка_n-f-aa 0.1353352832366127\n",
      "rus_младенец_n-m-aa 0.1353352832366127\n",
      "rus_дитя_n 0.1353352832366127\n",
      "rus_ребенок_n-m-aa 0.01831563888873418\n",
      "rus_ребёнок_n-m-aa 0.01831563888873418\n",
      "\n",
      "\t\t fra_enfant_n-mf-sg\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'enfant', d_l2, 'rus', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra_enfant_n-mf\n",
      "fra_enfant_n-m\n",
      "fra_enfant_n\n",
      "fra_enfant_n-mf-ND\n",
      "fra_enfant_n-m-ND\n",
      "fra_enfant_n-mf-pl\n",
      "fra_enfant_n-mf-sg\n",
      "fra_enfant_n-n\n"
     ]
    }
   ],
   "source": [
    "for i in G.nodes():\n",
    "    if i.lemma == 'enfant':\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben_prpers_prn-p3-infml-aa-mf-sg-gen\n",
      "cym_rhywun_prn-tn-m-sg-tn-m-sg\n",
      "kaz_сіз_prn-pers-p2-sg-frm-gen-subst-nom\n",
      "eng_you're_prn-subj-p2-mf-sp-vbser-pres\n",
      "sco_ye're_prn-subj-p2-mf-sp-vbser-pres\n",
      "fin_sama_adj-pos-sg-ess-n-sg-ess\n",
      "hbs_na_pr-acc-prn-pers-clt-p3-m-sg-acc\n",
      "hin_वह_prn-dem-p3-mf-sg-dst-nom\n",
      "hin_वह_prn-dem-p3-mf-pl-dst-nom\n",
      "ita_Milà_np-cog-cog-cog-cog-mf-sp\n"
     ]
    }
   ],
   "source": [
    "for node in G.nodes():\n",
    "    if len(node.s) > 6:\n",
    "        print (node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in d_l1:\n",
    "    if i.lemma not in d:\n",
    "        d[i.lemma] = set()\n",
    "    d[i.lemma].add('_'.join(i.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17975050961623681\n"
     ]
    }
   ],
   "source": [
    "a = [' | '.join(list(sorted(d[i]))) for i in d if len(d[i])>1]\n",
    "print(len(a)/len(d_l1))\n",
    "a = Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n | n_m_nn 2841\n",
      "n | n_f_nn 2549\n",
      "n | n_m_aa 1178\n",
      "adj_sint | n 1149\n",
      "n | n_nt_nn 921\n",
      "adj | adj_sint | n 586\n",
      "adj | adj_sint 382\n",
      "n | vblex_perf | vblex_perf_tv 353\n",
      "n | vblex_perf_tv 344\n",
      "n | n_f | n_f_nn 287\n",
      "n | n_m | n_m_nn 265\n",
      "vblex_perf | vblex_perf_tv 251\n",
      "adv | n 236\n",
      "n | vblex_impf 218\n",
      "n | vblex_impf_tv 210\n",
      "n | n_f_aa 197\n",
      "n | vblex_impf | vblex_impf_tv 190\n",
      "adj | n 183\n",
      "vblex_impf | vblex_impf_tv 154\n",
      "n_m_aa | n_m_nn 132\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(a, key=a.get, reverse=True)[:20]:\n",
    "    print (i, a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in d_l2:\n",
    "    if i.lemma not in d:\n",
    "        d[i.lemma] = set()\n",
    "    d[i.lemma].add('_'.join(i.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [d[i] for i in d if 'n' in d[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2980614543114543"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)/len([i.lemma for i in d_l2 if 'n' in i.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17001942380570761\n",
      "n | n_f 2496\n",
      "n | n_m 1651\n",
      "np | np_cog_mf_sp 811\n",
      "adj | n 583\n",
      "adj | adj_mf 386\n",
      "np | np_ant | np_ant_m_sg 330\n",
      "np | np_cog 325\n",
      "np | np_loc_f 311\n",
      "np | np_ant | np_ant_f_sg 288\n",
      "adj | n_m 257\n",
      "np | np_ant 230\n",
      "adj | adj_GD | adj_f | adj_m 193\n",
      "adj | n | n_m 172\n",
      "n_f | n_m 166\n",
      "np | np_ant_m_sg 118\n",
      "n | n_mf 117\n",
      "np_ant_f_sg | np_cog_mf_sp 98\n",
      "np | np_cog | np_cog_mf_sp 84\n",
      "adj | n | n_mf 83\n",
      "num | num_mf_sp 83\n"
     ]
    }
   ],
   "source": [
    "a = [' | '.join(list(sorted(d[i]))) for i in d if len(d[i])>1]\n",
    "print(len(a)/len(d_l2))\n",
    "a = Counter(a)\n",
    "for i in sorted(a, key=a.get, reverse=True)[:20]:\n",
    "    print (i, a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for every bidix\n",
    "- get relevant\n",
    "- try 4 max\n",
    "- exclude pair (skip)\n",
    "- for every word in actual bidix find best translation\n",
    "- compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg cat 35\n",
      "bel rus 35\n",
      "chv rus 25\n",
      "chv tat 25\n",
      "chv tur 25\n",
      "cos ita 36\n",
      "eus fin 30\n",
      "eus sme 30\n",
      "grn spa 32\n",
      "guc spa 32\n",
      "kir uzb 21\n",
      "kpv fin 27\n",
      "krl olo 26\n",
      "liv fin 26\n",
      "mrj fin 26\n",
      "myv fin 26\n",
      "oci cat 36\n",
      "oci fra 36\n",
      "oci spa 36\n",
      "olo fin 26\n",
      "quz spa 32\n",
      "rum ita 35\n",
      "scn spa 32\n",
      "udm kpv 36\n",
      "udm rus 36\n",
      "wel spa 32\n",
      "zho spa 32\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "    for fl in files :\n",
    "        pair = fl.replace('.dix', '').split('-')\n",
    "        one_comparison(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant (l1, l2):\n",
    "    G = nx.Graph()\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix', '').split('-')\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "    pair = [l(l1), l(l2)]\n",
    "    nodes = set()\n",
    "    i = 2\n",
    "    w = nx.single_source_shortest_path_length(G, pair[0], cutoff=i)\n",
    "    v = nx.single_source_shortest_path_length(G, pair[1], cutoff=i)\n",
    "    H = G.subgraph(w.keys())\n",
    "    H.remove_node(pair[0])\n",
    "    H2 = G.subgraph(v.keys())\n",
    "    H2.remove_node(pair[1])\n",
    "    if pair[1] in H.nodes():\n",
    "        v = nx.node_connected_component(H, pair[1])\n",
    "    else:\n",
    "        v = set()\n",
    "    if pair[0] in H2.nodes():\n",
    "        w = nx.node_connected_component(H, pair[1])\n",
    "    else:\n",
    "        w = set() \n",
    "    nodes = v & w | set([pair[0], pair[1]])\n",
    "    #if len(nodes) > 20 and len(nodes) < 40:\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_comparison(l1_m, l2_m):\n",
    "    logging.info('Start\\t'+'{}\\t{}'.format(l1_m, l2_m))\n",
    "    nodes = relevant (l1_m, l2_m)\n",
    "    #print (nodes)\n",
    "    with open('language_list.csv','w', encoding='utf-8') as f:\n",
    "        for node in nodes:\n",
    "            f.write('{}\\t{}\\n'.format(4, node))\n",
    "    G = nx.DiGraph()\n",
    "    logging.info('Start loading')\n",
    "    for T, l1, l2 in load_chosen():\n",
    "        if not (l1 in [l1_m, l2_m] and l2 in [l1_m, l2_m]):\n",
    "            add_bidix(G, T, l1, l2)\n",
    "    d1_t, d2_t = dictionaries(G, l1_m, l2_m)\n",
    "    logging.info('Finish loading')\n",
    "    return G, d1_t, d2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-23 20:23:30,991 | INFO : Start\teng\trus\n",
      "2018-05-23 20:23:31,003 | INFO : Start loading\n",
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-fas.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "lit lav\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "2018-05-23 20:27:33,874 | INFO : Finish loading\n"
     ]
    }
   ],
   "source": [
    "G, d1_t, d2_t = one_comparison('eng', 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92083"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exact_search (G, word, lang, cutoff):\n",
    "    results = {}\n",
    "    if word in G:\n",
    "        s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "        #print ('all: ', str(len(s)), end='\\t')\n",
    "        s = s.lang(lang)\n",
    "        #print ('filtered: ', str(len(s)))\n",
    "        for translation in s:\n",
    "            t = list(nx.all_simple_paths(G, word, translation, cutoff=cutoff))\n",
    "            t = [len(i) for i in t]\n",
    "            t = Counter(t)\n",
    "            coef = 0\n",
    "            for i in t:\n",
    "                coef += exp(-t[i])\n",
    "            results[str(translation)] = coef\n",
    "        if results:\n",
    "            for j in sorted(results, key=results.get, reverse=True)[:7]:\n",
    "                #return [word, j, results[j]]\n",
    "                return [str(word), str(j), str(results[j])]\n",
    "        else:\n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bel_школа_n', 'rus_школа_n', '0.503214724408055']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_search (G, Word('школа','bel',['n']), 'rus', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('test.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in d1_t:\n",
    "        result = exact_search (G, i, 'rus', 4)\n",
    "        if result:\n",
    "            f.write('\\t'.join(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x1f6a9abe390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.parse('./dictionaries/arg-cat.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_language(lang):\n",
    "    dictionary = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if lang in pair:\n",
    "                print (fl)\n",
    "                try:\n",
    "                    t = ET.parse(root+fl)\n",
    "                    for word1, word2, side in parse_bidix (t, pair[0], pair[1]):\n",
    "                        #word1 = str(word1)\n",
    "                        #word2 = str(word2)\n",
    "                        if lang == pair[0]:\n",
    "                            dictionary[word1.lemma]['-'.join(word1.s)] += 1\n",
    "                        else:\n",
    "                            dictionary[word2.lemma]['-'.join(word2.s)] += 1\n",
    "                except:\n",
    "                    pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'word': 1})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ava-rus.dix\n",
      "bel-rus.dix\n",
      "bul-rus.dix\n",
      "ces-rus.dix\n",
      "chv-rus.dix\n",
      "epo-rus.dix\n",
      "hbs-rus.dix\n",
      "isl-rus.dix\n",
      "kaz-rus.dix\n",
      "kom-rus.dix\n",
      "pol-rus.dix\n",
      "rus-eng.dix\n",
      "rus-ukr.dix\n",
      "tat-rus.dix\n",
      "udm-rus.dix\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%time dictionary = load_language('rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69366"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91724"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for i in dictionary:\n",
    "    k += len(dictionary[i])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f-aa': 11, 'n-f': 1, 'n': 3})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['собака']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f-aa': 11})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['кошка']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f': 1, 'n': 1, 'n-f-nn': 5})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['дверь']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'vblex-impf': 21, 'vblex-impf-iv': 9, 'n': 2, 'vblex-imperf': 4})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['идти']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get (w):\n",
    "    for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = set()\n",
    "for i in dictionary:\n",
    "    w = w | set(dictionary[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = set()\n",
    "for i in w:\n",
    "    v = v | set(i.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SPA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 17,\n",
       "             'n-f': 18,\n",
       "             'n-m-sg': 1,\n",
       "             'n-m-pl': 1,\n",
       "             'adj-mf': 7,\n",
       "             'n': 9,\n",
       "             'adj': 9,\n",
       "             'adj-mf-sg': 4,\n",
       "             'adj-mf-pl': 2,\n",
       "             'n-f-sg': 5})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n': 145, 'vblex': 7, 'n-ND': 3, 'np': 1, 'n-sg': 1, '': 1})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n': 81, 'vblex': 12, 'n-sg': 1})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['pen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 78\n",
      "n-ND 1\n",
      "n-sg 2\n",
      "vblex 5\n"
     ]
    }
   ],
   "source": [
    "word = 'gun'\n",
    "beginning = ''\n",
    "for key in sorted(dictionary[word]):\n",
    "    #if re.match('^'+beginning, key):\n",
    "    print(key, dictionary[word][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FRA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f': 12, 'n-f-ND': 1, 'n': 6})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['porte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-mf': 23,\n",
       "             'n-m': 8,\n",
       "             'np-ant': 1,\n",
       "             'adj': 1,\n",
       "             'n': 7,\n",
       "             'n-mf-ND': 2,\n",
       "             'n-m-ND': 1,\n",
       "             'n-mf-pl': 6,\n",
       "             'n-mf-sg': 1,\n",
       "             'n-n': 1})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['enfant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 60, 'n-m-ND': 3, 'n': 20, 'm': 1})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['coup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 20, 'm-sg': 1, 'n': 17, 'n-m-ND': 2})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['jour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dictionary:\n",
    "    if len(dictionary[i]) > 5:\n",
    "        print (i, ' | '.join(dictionary[i].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <= + frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [[1,2,3],[4,5,6]]\n",
    "[1,2,3] in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, s=[]):\n",
    "        self.lemma = lemma\n",
    "        self.lang = lang\n",
    "        self.s = s\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.s:\n",
    "            if isinstance(self.s[0],list):\n",
    "                w = '['+'|'.join(['-'.join(i) for i in self.s])+']'\n",
    "            else:\n",
    "                w = '['+'-'.join(self.s)+']'\n",
    "        else:\n",
    "            w = '-'\n",
    "        return str(self.lang)+'_'+str(self.lemma)+'_'+str(w)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and (self.s == other.s or other.s in self.s or self.s in other.s)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        if self.lang == other.lang:\n",
    "            if self.lemma == other.lemma:\n",
    "                s1 = set(self.s)\n",
    "                s2 = set(other.s)\n",
    "                if not s1 - s2 and s1&s2==s1:\n",
    "                    return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_f_[n-adj|v]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('f','f',[['n','adj'],['v']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('f','f',[['n','adj'],['v']]) == Word('f','f',['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [Word('f','f',[['n','adj'],['v']])]\n",
    "Word('f','f',['v']) in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordDict(dict):\n",
    "    def lemma(self, lemma):\n",
    "        self.lemma = lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tags(list):\n",
    "    def __le__(self, other):\n",
    "        s1 = set(self)\n",
    "        s2 = set(other)\n",
    "        if not s1 - s2 and s1&s2==s1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        s1 = set(self)\n",
    "        s2 = set(other)\n",
    "        if (not s1 - s2) and (s1&s2==s1) and (s2 - s1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '-'.join(self)\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FilteredDict(dict):\n",
    "    def set_lang(self, lang):\n",
    "        self.lang = lang\n",
    "    \n",
    "    def lemma(self, lemma):\n",
    "        return self[self.lang+'_'+lemma]\n",
    "        \n",
    "    def add(self, word):\n",
    "        lemma = word.lang+'_'+word.lemma\n",
    "        tags = Tags(word.s)\n",
    "        if lemma in self:\n",
    "            if tags in self[lemma]:\n",
    "                self[lemma][tags] += 1\n",
    "            else:\n",
    "                self[lemma][tags] = 1\n",
    "        else:\n",
    "            self[lemma] = WordDict()\n",
    "            self[lemma].lemma(lemma)\n",
    "            self[lemma][tags] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('пень','rus',['n']) < Word('пень','rus',['n','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_language_dict(lang):\n",
    "    dictionary = FilteredDict()\n",
    "    dictionary.set_lang(lang)\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if lang in pair:\n",
    "                print (fl)\n",
    "                try:\n",
    "                    t = ET.parse(root+fl)\n",
    "                    for word1, word2, side in parse_bidix (t, pair[0], pair[1]):\n",
    "                        if lang == pair[0]:\n",
    "                            dictionary.add(word1)\n",
    "                            #if len(word1.lemma) > 15:\n",
    "                            #    print (word1.lemma)\n",
    "                        else:\n",
    "                            dictionary.add(word2)\n",
    "                            #if len(word2.lemma) > 15:\n",
    "                            #    print (word2.lemma)\n",
    "                except:\n",
    "                    pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ava-rus.dix\n",
      "bel-rus.dix\n",
      "bul-rus.dix\n",
      "ces-rus.dix\n",
      "chv-rus.dix\n",
      "epo-rus.dix\n",
      "hbs-rus.dix\n",
      "isl-rus.dix\n",
      "kaz-rus.dix\n",
      "kom-rus.dix\n",
      "pol-rus.dix\n",
      "rus-eng.dix\n",
      "rus-ukr.dix\n",
      "tat-rus.dix\n",
      "udm-rus.dix\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%time rus = one_language_dict('rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{n-f-aa: 3, n-f-nn: 3}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus.lemma('мама')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{n-f-aa: 3, n-f-nn: 3}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus['rus_мама']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rus_мама'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus.lemma('мама').lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(word_dict):\n",
    "    short = []\n",
    "    for i in sorted(word_dict, key=lambda x: (word_dict[x], -len(x)), reverse=True):\n",
    "        if not short:\n",
    "            short.append(i)\n",
    "        t = True\n",
    "        for j in short:\n",
    "            #print (short, list(i), list(j), str(j <= i), str(i <= j))\n",
    "            if (j <= i or i <= j):\n",
    "                t = False\n",
    "        if i not in short and t:\n",
    "            short.append(i)\n",
    "    return word_dict.lemma, short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shorten(word_dict):\n",
    "    short = []\n",
    "    for i in sorted(word_dict, key=lambda x: (word_dict[x], -len(x)), reverse=True):\n",
    "        t = True\n",
    "        for key, j in enumerate(short):\n",
    "            #print ((j))\n",
    "            #j = Tags(j)\n",
    "            #print (i, j[0])\n",
    "            if (j[0] < i) or (i < j[0]):\n",
    "                #print (j[0] < i)\n",
    "                #print (i < j[0])\n",
    "                short[key].append(i)\n",
    "                t = False\n",
    "                break\n",
    "        if t:\n",
    "            short.append([i])\n",
    "    return word_dict.lemma, short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('папа', {n-m: 1, n-m-aa: 1}, ('rus_папа', [[n-m, n-m-aa]]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('папа', rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tags(['n','m','aa']) < Tags(['n','m','nn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if set([1,2,3]) & set([1,2,4]) == set([1,2]):\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['n','m','aa'] < ['n','m','nn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-m-aa n-m-nn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('поп', {n-m-aa: 1, n-m-nn: 2}, ('rus_поп', [[n-m-nn], [n-m-aa]]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('поп', rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-m n-m-nn\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('дом', {n-m-nn: 11, n-m: 1}, ('rus_дом', [[n-m-nn, n-m]]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('дом', rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('по счастливой случайности',\n",
       " {adv: 1},\n",
       " ('rus_по счастливой случайности', [[adv]]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('по счастливой случайности', rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rus_папа', [[n-m], [n-m-aa]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(rus.lemma('папа'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rus_мама', [[n-f-aa, n-f-nn]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(rus.lemma('мама'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rus_печь', [[n-f-aa]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(rus.lemma('печь'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{n-m-nn: 3, n-m: 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus.lemma('снег')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rus_снег', [[n-m-nn, n-m]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten(rus.lemma('снег'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo (rus):\n",
    "    k = 0\n",
    "    for i in rus:\n",
    "        k += len(shorten(rus[i])[1])\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 347 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47481"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time foo(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49748"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for i in rus:\n",
    "    k += len(rus[i])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([8])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {4:8}\n",
    "d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49748"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for i in rus:\n",
    "    k += sum(rus[i].values())\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49748"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time foo(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shorten(rus['rus_папа'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rus['rus_папа'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printt(lemma, rus):\n",
    "    return lemma, rus.lemma(lemma), shorten(rus.lemma(lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_lang(lang):\n",
    "    rus = one_language_dict(lang)\n",
    "    k = 0\n",
    "    for i in rus:\n",
    "        k += len(shorten(rus[i])[1])\n",
    "    print (k)    \n",
    "    k = 0\n",
    "    for i in rus:\n",
    "        k += len(rus[i].keys())\n",
    "    print (k)\n",
    "    return rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ava-rus.dix\n",
      "bel-rus.dix\n",
      "bul-rus.dix\n",
      "ces-rus.dix\n",
      "chv-rus.dix\n",
      "epo-rus.dix\n",
      "hbs-rus.dix\n",
      "isl-rus.dix\n",
      "kaz-rus.dix\n",
      "kom-rus.dix\n",
      "pol-rus.dix\n",
      "rus-eng.dix\n",
      "rus-ukr.dix\n",
      "tat-rus.dix\n",
      "udm-rus.dix\n",
      "47358\n",
      "49748\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%time rus = check_lang('rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(rus.keys())[:50000]:\n",
    "    w = rus[str(i)]\n",
    "    if len(w)>1:\n",
    "        v = shorten(w)\n",
    "        if len(v[1])<len(w):\n",
    "            print (w, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asm-eng.dix\n",
      "ben-eng.dix\n",
      "bul-eng.dix\n",
      "ckb-eng.dix\n",
      "cym-eng.dix\n",
      "ell-eng.dix\n",
      "eng-afr.dix\n",
      "eng-cat.dix\n",
      "eng-deu.dix\n",
      "eng-gle.dix\n",
      "eng-glg.dix\n",
      "eng-hin.dix\n",
      "eng-ina.dix\n",
      "eng-ita.dix\n",
      "eng-kaz.dix\n",
      "eng-lit.dix\n",
      "eng-lvs.dix\n",
      "eng-mlt.dix\n",
      "eng-nld.dix\n",
      "eng-pes.dix\n",
      "eng-pol.dix\n",
      "eng-por.dix\n",
      "eng-sco.dix\n",
      "eng-spa.dix\n",
      "eng-sqi.dix\n",
      "eng-srn.dix\n",
      "eng-tel.dix\n",
      "epo-eng.dix\n",
      "eus-eng.dix\n",
      "fin-eng.dix\n",
      "fra-eng.dix\n",
      "gle-eng.dix\n",
      "hat-eng.dix\n",
      "haw-eng.dix\n",
      "hbs-eng.dix\n",
      "hun-eng.dix\n",
      "hye-eng.dix\n",
      "isl-eng.dix\n",
      "kmr-eng.dix\n",
      "lat-eng.dix\n",
      "mal-eng.dix\n",
      "mar-eng.dix\n",
      "mfe-eng.dix\n",
      "mkd-eng.dix\n",
      "nep-eng.dix\n",
      "nor-eng.dix\n",
      "pes-eng.dix\n",
      "rus-eng.dix\n",
      "sah-eng.dix\n",
      "sin-eng.dix\n",
      "sjo-eng.dix\n",
      "swa-eng.dix\n",
      "swe-eng.dix\n",
      "tat-eng.dix\n",
      "tha-eng.dix\n",
      "tur-eng.dix\n",
      "vie-eng.dix\n",
      "83977\n",
      "103472\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%time eng = check_lang('eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mother', {n: 54, n-sg: 1}, ('eng_mother', [n]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('mother', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('foot', {n: 49, n-sg: 1}, ('eng_foot', [n]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('foot', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go', {vblex: 217, ij: 2}, ('eng_go', [vblex, ij]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('go', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bre-fra.dix\n",
      "byv-fra.dix\n",
      "epo-fra.dix\n",
      "eus-fra.dix\n",
      "fin-fra.dix\n",
      "fra-cat.dix\n",
      "fra-eng.dix\n",
      "fra-ina.dix\n",
      "fra-ita.dix\n",
      "fra-nld.dix\n",
      "fra-por.dix\n",
      "fra-ron.dix\n",
      "fra-spa.dix\n",
      "oci-fra.dix\n",
      "29825\n",
      "38646\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%time fra = check_lang('fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enfant',\n",
       " {n-mf: 10, n-m: 4, np-ant: 1, n: 1},\n",
       " ('fra_enfant', [n-mf, n-m, np-ant]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printt('enfant', fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [1]\n",
    "[1] == s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load shorten dictionary to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_to_nodes(dictionary):\n",
    "    for i in list(dictionary.keys())[:10]:\n",
    "        lang, word = i.split('_')\n",
    "        tags = [list(j) for j in dictionary[i]]\n",
    "        if len(tags) == 1:\n",
    "            tags = tags[0]\n",
    "        #print (lang, word, tags)\n",
    "        yield Word(word, lang, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object dictionary_to_nodes at 0x0000022F78F5B888>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_to_nodes(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for i in dictionary_to_nodes(rus):\n",
    "    G.add_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rus_бы_[part],\n",
       " rus_ли_[part],\n",
       " rus_же_[part|cnjadv],\n",
       " rus_г._[abbr],\n",
       " rus_гг._[abbr],\n",
       " rus_см._[abbr],\n",
       " rus_кг_[abbr],\n",
       " rus_км_[abbr],\n",
       " rus_мг_[abbr],\n",
       " rus_млн_[abbr]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_to_nodes(dictionary):\n",
    "    for i in dictionary:\n",
    "        try:\n",
    "            lang, word = i.split('_')\n",
    "            tags = [list(j) for j in dictionary[i]]\n",
    "            if len(tags) == 1:\n",
    "                tags = tags[0]\n",
    "                yield Word(word, lang, tags)\n",
    "            else:\n",
    "                for i in tags:\n",
    "                    yield Word(word, lang, i)\n",
    "        except:\n",
    "            lang, word = i[:4], i[4:].replace('_',' ')\n",
    "            tags = [list(j) for j in dictionary[i]]\n",
    "            if len(tags) == 1:\n",
    "                tags = tags[0]\n",
    "                yield Word(word, lang, tags)\n",
    "            else:\n",
    "                for i in tags:\n",
    "                    yield Word(word, lang, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for i in dictionary_to_nodes(rus):\n",
    "    G.add_node(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46534"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rus_черное_дерево\n",
      "rus_ черное дерево\n",
      "rus_политическое_убийство\n",
      "rus_ политическое убийство\n",
      "rus_брачный_союз\n",
      "rus_ брачный союз\n",
      "rus_атмосферные_осадки\n",
      "rus_ атмосферные осадки\n",
      "rus_поражение_электрическим_током\n",
      "rus_ поражение электрическим током\n",
      "rus_сельское_хозяйство\n",
      "rus_ сельское хозяйство\n",
      "rus_охрана_природы\n",
      "rus_ охрана природы\n",
      "rus_время_года\n",
      "rus_ время года\n",
      "rus_горная_порода\n",
      "rus_ горная порода\n"
     ]
    }
   ],
   "source": [
    "for i in rus:\n",
    "    if len(i.split('_'))>2:\n",
    "        print (i)\n",
    "        print (i[:4], i[4:].replace('_',' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_language_dict(lang):\n",
    "    dictionary = FilteredDict()\n",
    "    dictionary.set_lang(lang)\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if lang in pair:\n",
    "                try:\n",
    "                    t = ET.parse(root+fl)\n",
    "                    for word1, word2, side in parse_bidix (t, pair[0], pair[1]):\n",
    "                        if lang == pair[0]:\n",
    "                            dictionary.add(word1)\n",
    "                        else:\n",
    "                            dictionary.add(word2)\n",
    "                except GeneratorExit:\n",
    "                    pass\n",
    "                except:\n",
    "                    pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_nodes (G, languages):\n",
    "    logging.info('Start loading nodes')\n",
    "    for lang in languages:\n",
    "        dictionary = one_language_dict(lang)\n",
    "        for node in dictionary_to_nodes(dictionary):\n",
    "            G.add_node(node)\n",
    "        print(lang, end='\\t')\n",
    "    print ('', end='\\n')\n",
    "    logging.info('Finish loading nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def existance(pair, nodes):\n",
    "    if pair[0] in nodes and pair[1] in nodes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_chosen():\n",
    "    with open ('language_list.csv','r',encoding='utf-8') as f:\n",
    "        languages = set([i.split('\\t')[1].strip() for i in f.readlines()])\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files:\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if existance(pair, languages):\n",
    "                #try:\n",
    "                #    with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                #        dictionary = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))\n",
    "                #        yield ET.fromstring(dictionary), pair[0], pair[1]\n",
    "                #except:\n",
    "                #    pass\n",
    "                with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                        dictionary = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))\n",
    "                        yield dictionary, pair[0], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_edges (G):\n",
    "    logging.info('Start loading edges')\n",
    "    for T, l1, l2 in load_chosen():\n",
    "        for word1, word2, side in parse_bidix (T, l1, l2):\n",
    "            try:\n",
    "                word1 = G.nodes()[G.nodes().index(word1)]\n",
    "                word2 = G.nodes()[G.nodes().index(word2)]\n",
    "                if side == None:\n",
    "                    G.add_edge(word1, word2)\n",
    "                    G.add_edge(word2, word1)\n",
    "                elif side == 'LR': G.add_edge(word1, word2)\n",
    "                elif side == 'RL': G.add_edgr(word2, word1)\n",
    "            except:\n",
    "                print (word1, word2)\n",
    "        print ('{}-{}'.format(l1, l2), end='\\t')\n",
    "    print ('', end='\\n')\n",
    "    logging.info('Finish loading edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    logging.info('Start')\n",
    "    G = nx.DiGraph()\n",
    "    with open ('language_list.csv','r',encoding='utf-8') as f:\n",
    "        languages = set([i.split('\\t')[1].strip() for i in f.readlines()])\n",
    "    load_nodes (G, languages)\n",
    "    load_edges (G)\n",
    "    logging.info('Finish')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_relevant_languages('rus', 'fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time G = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.3 ms ± 3.46 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit word1 = G.nodes()[G.nodes().index(Word('мама','rus',['n','f','aa']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405563"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = Word('лес','rus',['n']), Word('лес','rus',[['n'],['v']]), Word('рубка','rus',[['n'],['v']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from([w1,w2,w3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rus_лес_[n], rus_лес_[n|v], rus_рубка_[n|v]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edge(w3,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(rus_рубка_[n|v], rus_лес_[n|v])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w4 = Word('рубка','rus',['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Word"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(G.nodes()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4 in G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rus_рубка_[n|v]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4 = G.nodes()[G.nodes().index(w4)]\n",
    "w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(w4,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(rus_рубка_[n|v], rus_лес_[n|v])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edge(Word('рубка','rus',['v']),w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare monodictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
