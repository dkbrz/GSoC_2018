{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool.func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filelist.txt','r') as f:\n",
    "    file_list = f.readlines()\n",
    "file_list = [i.strip() for i in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    try:\n",
    "        tree = ET.parse(file)\n",
    "        for section in tree.findall('section'):\n",
    "            vr = section.findall(\".//*[@vr]\")\n",
    "            if vr: print ('vr\\t', file.split('.')[-2], len(vr))\n",
    "            vl = section.findall(\".//*[@vl]\")\n",
    "            if vl: print ('vl\\t', file.split('.')[-2], len(vl))\n",
    "    except: print ('\\t\\t\\t\\t', file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vr\t arg-cat 6 {'cat': 3, 'val_gva val_uni': 3}\n",
      "vr\t dan-nor 9944 {'nob': 5018, 'nno': 4925, 'nor': 1}\n",
      "vr\t eng-cat 495 {'val': 258, 'cat': 234, 'eng': 3}\n",
      "vl\t eng-cat 80 {'en_GB': 40, 'en_US': 40}\n",
      "\t\t\t\t eo-bg\n",
      "\t\t\t\t eo-fa\n",
      "\t\t\t\t eo-pl\n",
      "vr\t fao-nor 2254 {'nob': 1057, 'nno': 1197}\n",
      "vr\t fra-cat 3 {'val': 2, 'cat': 1}\n",
      "vr\t fra-por 550 {'br': 276, 'pt': 274}\n",
      "vr\t ita-nor 696 {'nno': 348, 'nob': 348}\n",
      "vl\t nor-eng 140 {'nob': 68, 'nno': 72}\n",
      "\t\t\t\t pl-lv\n",
      "\t\t\t\t sah-eng\n",
      "vr\t spa-cat 997 {'cat': 477, 'val_gva val_uni': 466, 'cat val_gva val_uni': 1, 'cat val_uni': 17, 'val_gva': 19, 'val_uni': 3, 'cat val_gva': 2, 'val_uni val_gva': 11, 'val': 1}\n",
      "vr\t swe-nor 7394 {'nno': 3643, 'nob': 3751}\n",
      "vr\t swe-nor 9350 {'nno': 8147, 'nob': 1203}\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    try:\n",
    "        tree = ET.parse(file)\n",
    "        for section in tree.findall('section'):\n",
    "            vr = section.findall(\".//*[@vr]\")\n",
    "            vr_n = {}\n",
    "            for i in vr:\n",
    "                if i.attrib['vr'] not in vr_n: vr_n[i.attrib['vr']] = 1\n",
    "                else: vr_n[i.attrib['vr']] += 1\n",
    "            if vr: print ('vr\\t', file.split('.')[-2], len(vr), vr_n)\n",
    "            vl = section.findall(\".//*[@vl]\")\n",
    "            vl_n = {}\n",
    "            for i in vl:\n",
    "                if i.attrib['vl'] not in vl_n: vl_n[i.attrib['vl']] = 1\n",
    "                else: vl_n[i.attrib['vl']] += 1\n",
    "            if vl: print ('vl\\t', file.split('.')[-2], len(vl), vl_n)\n",
    "    except: print ('\\t\\t\\t\\t', file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val', 'gva', '']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'val_gva'.split('_')\n",
    "s.append('')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'section' at 0x000002344D632C28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.Element('section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arg', 'cat']\n",
      "arg-cat 7\n",
      "arg-cat_cat 11\n",
      "arg-cat_val_gva 15\n",
      "arg-cat_val_uni 15\n",
      "\n",
      "['dan', 'nor']\n",
      "dan-nor 7\n",
      "dan-nor_nob 11\n",
      "dan-nor_nno 11\n",
      "dan-nor_nor 11\n",
      "\n",
      "['eng', 'cat']\n",
      "eng-cat 7\n",
      "eng-cat_val 11\n",
      "eng-cat_cat 11\n",
      "eng_en_GB-cat 13\n",
      "eng_en_US-cat 13\n",
      "eng_en_US-cat_val 17\n",
      "eng_en_US-cat_cat 17\n",
      "eng_en_GB-cat_val 17\n",
      "eng_en_GB-cat_cat 17\n",
      "eng-cat_eng 11\n",
      "\n",
      "\t\t\t\t eo-bg\n",
      "\t\t\t\t eo-fa\n",
      "\t\t\t\t eo-pl\n",
      "['fao', 'nor']\n",
      "fao-nor 7\n",
      "fao-nor_nob 11\n",
      "fao-nor_nno 11\n",
      "\n",
      "['fra', 'cat']\n",
      "fra-cat 7\n",
      "fra-cat_val 11\n",
      "fra-cat_cat 11\n",
      "\n",
      "['fra', 'por']\n",
      "fra-por 7\n",
      "fra-por_br 10\n",
      "fra-por_pt 10\n",
      "\n",
      "['ita', 'nor']\n",
      "ita-nor 7\n",
      "ita-nor_nno 11\n",
      "ita-nor_nob 11\n",
      "\n",
      "['nor', 'eng']\n",
      "nor-eng 7\n",
      "nor_nob-eng 11\n",
      "nor_nno-eng 11\n",
      "\n",
      "\t\t\t\t pl-lv\n",
      "\t\t\t\t sah-eng\n",
      "['spa', 'cat']\n",
      "spa-cat 7\n",
      "spa-cat_cat 11\n",
      "spa-cat_val_gva 15\n",
      "spa-cat_val_uni 15\n",
      "spa-cat_val 11\n",
      "\n",
      "['swe', 'nor']\n",
      "swe-nor_nno 11\n",
      "swe-nor_nob 11\n",
      "swe-nor 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    filename = file.split('.')[-2].split('-')\n",
    "    try:\n",
    "    #if True:\n",
    "        tree = ET.parse(file)\n",
    "        result = {}\n",
    "        for section in tree.findall('section'):\n",
    "            for i in section:\n",
    "                name = []\n",
    "                if not 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                    name = [filename[0]+'-'+filename[1]]\n",
    "                elif 'vr' in i.attrib and not 'vl' in i.attrib:\n",
    "                    name = [filename[0]+'-'+filename[1]+'_' + j for j in i.attrib['vr'].split(' ')]\n",
    "                elif 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                    name = [filename[0]+'_'+j +'-'+filename[1] for j in i.attrib['vl'].split(' ')]\n",
    "                else:\n",
    "                    #print (i.attrib['vl'].split(' '), i.attrib['vr'].split(' '))\n",
    "                    for j in i.attrib['vl'].split(' '):\n",
    "                        for k in i.attrib['vr'].split(' '):\n",
    "                            name.append(filename[0]+'_'+j+'-'+filename[1]+'_'+k)\n",
    "                    #print (name)\n",
    "                for j in name:\n",
    "                    if j not in result: result[j] = ET.Element('section')\n",
    "                    result[j].append(i)\n",
    "        \n",
    "        if len (result) > 1:\n",
    "            print (filename)\n",
    "            for i in result:\n",
    "                print (i, len(i))\n",
    "            print ()\n",
    "    except: print ('\\t\\t\\t\\t', file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dialects():\n",
    "    with open('filelist.txt','r') as f:\n",
    "        file_list = f.readlines()\n",
    "    file_list = [i.strip() for i in file_list]\n",
    "    for file in file_list:\n",
    "        if not os.path.exists('./dictionaries/'): os.makedirs('./dictionaries/')\n",
    "        filename = file.split('.')[-2].split('-')\n",
    "        try:\n",
    "        #if True:\n",
    "            tree = ET.parse(file)\n",
    "            result = {}\n",
    "            for section in tree.findall('section'):\n",
    "                for i in section:\n",
    "                    name = []\n",
    "                    if not 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                        name = [filename[0]+'-'+filename[1]]\n",
    "                    elif 'vr' in i.attrib and not 'vl' in i.attrib:\n",
    "                        name = [filename[0]+'-'+j for j in i.attrib['vr'].split(' ')]\n",
    "                    elif 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                        name = [j +'-'+filename[1] for j in i.attrib['vl'].split(' ')]\n",
    "                    else:\n",
    "                        for j in i.attrib['vl'].split(' '):\n",
    "                            for k in i.attrib['vr'].split(' '):\n",
    "                                name.append(filename[0]+'_'+j+'-'+filename[1]+'_'+k)\n",
    "                    for j in name:\n",
    "                        if j not in result: result[j] = ET.Element('section')\n",
    "                        result[j].append(i)\n",
    "\n",
    "            if len (result) > 1:\n",
    "                print (filename)\n",
    "                for i in result:\n",
    "                    nm = i.split('-')\n",
    "                    nm = './dictionaries/apertium-{}-{}.{}-{}.dix'.format(filename[0], filename[1], nm[0], nm[1])\n",
    "                    ET.ElementTree(result[i]).write(nm, encoding='utf-8')\n",
    "                    with open(nm, 'r', encoding='utf-8') as f:\n",
    "                        xml = f.read()\n",
    "                    with open(nm, 'w', encoding='utf-8') as f:\n",
    "                        f.write(xml.replace('<e','\\n    <e').replace('</section>','\\n</section>'))    \n",
    "            print ('-'.join(filename))\n",
    "        except: print ('Error:\\t', file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arg', 'cat']\n",
      "./dictionaries/apertium-arg-cat..-/.dix\n",
      "./dictionaries/apertium-arg-cat..-/.dix\n",
      "./dictionaries/apertium-arg-cat..-/.dix\n",
      "./dictionaries/apertium-arg-cat..-/.dix\n",
      "['dan', 'nor']\n",
      "./dictionaries/apertium-dan-nor..-/.dix\n",
      "./dictionaries/apertium-dan-nor..-/.dix\n",
      "./dictionaries/apertium-dan-nor..-/.dix\n",
      "./dictionaries/apertium-dan-nor..-/.dix\n",
      "['eng', 'cat']\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "./dictionaries/apertium-eng-cat..-/.dix\n",
      "\t\t\t\t eo-bg\n",
      "\t\t\t\t eo-fa\n",
      "\t\t\t\t eo-pl\n",
      "['fao', 'nor']\n",
      "./dictionaries/apertium-fao-nor..-/.dix\n",
      "./dictionaries/apertium-fao-nor..-/.dix\n",
      "./dictionaries/apertium-fao-nor..-/.dix\n",
      "['fra', 'cat']\n",
      "./dictionaries/apertium-fra-cat..-/.dix\n",
      "./dictionaries/apertium-fra-cat..-/.dix\n",
      "./dictionaries/apertium-fra-cat..-/.dix\n",
      "['fra', 'por']\n",
      "./dictionaries/apertium-fra-por..-/.dix\n",
      "./dictionaries/apertium-fra-por..-/.dix\n",
      "./dictionaries/apertium-fra-por..-/.dix\n",
      "['ita', 'nor']\n",
      "./dictionaries/apertium-ita-nor..-/.dix\n",
      "./dictionaries/apertium-ita-nor..-/.dix\n",
      "./dictionaries/apertium-ita-nor..-/.dix\n",
      "['nor', 'eng']\n",
      "./dictionaries/apertium-nor-eng..-/.dix\n",
      "./dictionaries/apertium-nor-eng..-/.dix\n",
      "./dictionaries/apertium-nor-eng..-/.dix\n",
      "\t\t\t\t pl-lv\n",
      "\t\t\t\t sah-eng\n",
      "['spa', 'cat']\n",
      "./dictionaries/apertium-spa-cat..-/.dix\n",
      "./dictionaries/apertium-spa-cat..-/.dix\n",
      "./dictionaries/apertium-spa-cat..-/.dix\n",
      "./dictionaries/apertium-spa-cat..-/.dix\n",
      "./dictionaries/apertium-spa-cat..-/.dix\n",
      "['swe', 'nor']\n",
      "./dictionaries/apertium-swe-nor..-/.dix\n",
      "./dictionaries/apertium-swe-nor..-/.dix\n",
      "./dictionaries/apertium-swe-nor..-/.dix\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    if not os.path.exists('./dictionaries/'): os.makedirs('./dictionaries/')\n",
    "    filename = file.split('.')[-2].split('-')\n",
    "    try:\n",
    "    #if True:\n",
    "        tree = ET.parse(file)\n",
    "        result = {}\n",
    "        for section in tree.findall('section'):\n",
    "            for i in section:\n",
    "                name = []\n",
    "                if not 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                    name = [filename[0]+'-'+filename[1]]\n",
    "                elif 'vr' in i.attrib and not 'vl' in i.attrib:\n",
    "                    name = [filename[0]+'-'+filename[1]+'_' + j for j in i.attrib['vr'].split(' ')]\n",
    "                elif 'vl' in i.attrib and not 'vr' in i.attrib:\n",
    "                    name = [filename[0]+'_'+j +'-'+filename[1] for j in i.attrib['vl'].split(' ')]\n",
    "                else:\n",
    "                    for j in i.attrib['vl'].split(' '):\n",
    "                        for k in i.attrib['vr'].split(' '):\n",
    "                            name.append(filename[0]+'_'+j+'-'+filename[1]+'_'+k)\n",
    "                for j in name:\n",
    "                    if j not in result: result[j] = ET.Element('section')\n",
    "                    result[j].append(i)\n",
    "        \n",
    "        if len (result) > 1:\n",
    "            print (filename)\n",
    "            for i in result:\n",
    "                nm = i.split('-')\n",
    "                nm = './dictionaries/apertium-{}-{}.{}-{}.dix'.format(filename[0], filename[1], nm[0], nm[1])\n",
    "                ET.ElementTree(result[i]).write(nm, encoding='utf-8')\n",
    "                with open(nm, 'r', encoding='utf-8') as f:\n",
    "                    xml = f.read()\n",
    "                with open(nm, 'w', encoding='utf-8') as f:\n",
    "                    f.write(xml.replace('<e','\\n    <e').replace('</section>','\\n</section>'))    \n",
    "                print ('./dictionaries/apertium-{}-{}.{}-{}.dix'.format(filename[0], filename[1], nm[0], nm[1]))\n",
    "    except: print ('\\t\\t\\t\\t', file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Glaz\\\\Documents\\\\GitHub\\\\GSoC_2018\\\\dictionaries'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('./dictionaries/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool.func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_language_dict(lang):\n",
    "    \"Gather dictionary of one language from bidixes\"\n",
    "    dictionary = FilteredDict()\n",
    "    dictionary.set_lang(lang)\n",
    "    with open ('./filelist.txt','r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            pair = [l(i) for i in line.split('.')[-2].split('-')]\n",
    "            if '-'.join(pair) in rename: pair = rename['-'.join(pair)].split('-')\n",
    "            if lang in pair:\n",
    "                print (pair)\n",
    "                if lang == pair[0]: side = 'l'\n",
    "                else: side = 'r'\n",
    "                #try:\n",
    "                if True:\n",
    "                    with open (line, 'r', encoding='utf-8') as d:\n",
    "                        t = ET.fromstring(d.read().replace('<b/>',' ').replace('<.?g>',''))\n",
    "                    print (t)\n",
    "                    for word in parse_one(t, side, lang): \n",
    "                        print (word)\n",
    "                        dictionary.add(word)\n",
    "                #except: pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arg', 'val_gva']\n",
      "<Element 'section' at 0x00000229F7C64BD8>\n",
      "['spa', 'val_gva']\n",
      "<Element 'section' at 0x00000229F7C64548>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_language_dict('val_gva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAP'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sap'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPA-CAT'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants1, variants2 = ['spa'], ['cat']\n",
    "'{}-{}'.format(variants1[0].upper(), variants2[0].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(variants1, variants2):\n",
    "    with open ('{}-{}-merged'.format(variants1[0].upper(), variants2[0].upper()), 'w', encoding='utf-8') as result:\n",
    "        for i in variants1:\n",
    "            for j in variants2:\n",
    "                with open(\"{}-{}-new\".format(i, j), 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "                    if len(i.split('_')) > 1: i = '_'.join(i.split('_')[1:])\n",
    "                    if len(j.split('_')) > 1: j = '_'.join(j.split('_')[1:])    \n",
    "                    text = text.replace('<e', '<e vl=\\'{}\\' vr=\\'{}\\' '.format(i, j))\n",
    "                    result.write(text + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge(['spa'], ['cat','cat_val_uni'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
