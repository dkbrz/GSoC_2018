{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilingual dictionary enrichment via graph completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "import pandas as pd\n",
    "lang_codes = pd.read_csv('./files/language-codes-full_csv.csv', na_values = nan, sep='\\t', header=0)\n",
    "lang_codes = lang_codes[['3','2']]\n",
    "lang_codes = lang_codes.dropna()\n",
    "\n",
    "\n",
    "lang_codes = [{i[0]:i[1] for i in np.array(lang_codes)}, {i[1]:i[0] for i in np.array(lang_codes)}]\n",
    "\n",
    "with open ('./files/lang_codes.json', 'w') as f:\n",
    "    json.dump(lang_codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fra'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('./files/lang_codes.json', 'r') as f:\n",
    "    lang_codes = json.load(f)\n",
    "\n",
    "def l(lang, mode=3):\n",
    "    mode = mode % 2\n",
    "    if len(lang)==2:\n",
    "        if lang in lang_codes[mode]:\n",
    "            return lang_codes[mode][lang]\n",
    "        else:\n",
    "            return lang\n",
    "    else:\n",
    "        return lang\n",
    "l('fr', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load user with login and password from secret file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "with open ('secure.json') as f:\n",
    "    SECRET = json.loads(f.read())\n",
    "\n",
    "github = Github(SECRET['USER'], SECRET['PASSWORD'])\n",
    "\n",
    "user = github.get_user('apertium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user.get_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generator ** : yield all repos that match name pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repo_names(user):\n",
    "    for repo in user.get_repos():\n",
    "        if re.match('apertium-[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?', repo.name):\n",
    "            yield repo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like heavy function. But I don't see any improvements yet, except for having certain repo for all bidix copies. But this one above is the most up-to-date. It filters not languages pair repos, it is needed not to look for bidix where it can't be. Function saves a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%time w = list(repo_names(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find bidix **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length sorting to reduce number of files to check (bidix is lone of the longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    for i in sorted(repo.get_dir_contents('/'), key = lambda x: (len(x.path), 1000-ord(('   '+x.path)[-3])), reverse=True):\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix$', i.path):\n",
    "            return i.download_url\n",
    "        elif len(i.path) < 23:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 709 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/apertium/apertium-cat-srd/master/apertium-cat-srd.cat-srd.dix'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bidix_url(github.get_repo(user.name+'/'+w[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Only relevant for certain language pair **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are **164 ** pairs at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_all_bidixes(user):\n",
    "    logging.info('Start')\n",
    "    if not os.path.exists('./dictionaries/'):\n",
    "        os.makedirs('./dictionaries/')\n",
    "    for repo_name in repo_names(user):\n",
    "        bidix = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        langs = [l(i) for i in repo_name.split('-')[1:]]\n",
    "        filename = './dictionaries/'+'-'.join(langs)+'.dix'\n",
    "        if bidix:\n",
    "            response = requests.get(bidix)\n",
    "            response.encoding = 'UTF-8'\n",
    "            with open(filename, 'w', encoding='UTF-8') as f:\n",
    "                f.write(response.text)\n",
    "    logging.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-22 15:26:56,733 | INFO : Start\n",
      "2018-05-22 15:44:22,590 | INFO : Finish\n"
     ]
    }
   ],
   "source": [
    "download_all_bidixes(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_relevant_languages(l1, l2):\n",
    "    G = nx.Graph()\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix', '').split('-')\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "    pair = [l(l1), l(l2)]\n",
    "    with open('language_list.csv','w', encoding='utf-8') as f:\n",
    "        nodes = set()\n",
    "        for i in range(1,5):\n",
    "            w = nx.single_source_shortest_path_length(G, pair[0], cutoff=i)\n",
    "            v = nx.single_source_shortest_path_length(G, pair[1], cutoff=i)\n",
    "            H = G.subgraph(w.keys())\n",
    "            H.remove_node(pair[0])\n",
    "            H2 = G.subgraph(v.keys())\n",
    "            H2.remove_node(pair[1])\n",
    "            if pair[1] in H.nodes():\n",
    "                v = nx.node_connected_component(H, pair[1])\n",
    "            else:\n",
    "                v = set()\n",
    "            if pair[0] in H2.nodes():\n",
    "                w = nx.node_connected_component(H, pair[1])\n",
    "            else:\n",
    "                w = set() \n",
    "            nodes2 = v & w | set([pair[0], pair[1]])\n",
    "            nodes2 = nodes2 - nodes\n",
    "            for node in nodes2:\n",
    "                f.write('{}\\t{}\\n'.format(i*2, node))\n",
    "            nodes = nodes | nodes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_relevant_languages('bel', 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_languages():\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files:\n",
    "            #print (root+fl)\n",
    "            try:\n",
    "                s = ET.parse(root+fl)\n",
    "            except:\n",
    "                print ('ERROR :'+fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR :epo-bul.dix\n",
      "ERROR :epo-per.dix\n",
      "ERROR :epo-pol.dix\n",
      "ERROR :fin-fra.dix\n",
      "ERROR :pol-lav.dix\n",
      "ERROR :sah-eng.dix\n"
     ]
    }
   ],
   "source": [
    "check_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def existance(pair, nodes):\n",
    "    if pair[0] in nodes and pair[1] in nodes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_chosen():\n",
    "    with open ('language_list.csv','r',encoding='utf-8') as f:\n",
    "        languages = set([i.split('\\t')[1].strip() for i in f.readlines()])\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files:\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if existance(pair, languages):\n",
    "                try:\n",
    "                    with open (root+fl, 'r', encoding='utf-8') as d:\n",
    "                        dictionary = d.read().replace('<b/>',' ').replace('<.?g>','')\n",
    "                        yield ET.fromstring(dictionary), pair[0], pair[1]\n",
    "                except:\n",
    "                    print ('ERROR: ', fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-per.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time len(list(load_chosen()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Word **\n",
    "\n",
    "- lemma : lemma\n",
    "- lang : language\n",
    "- pos : part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, s=[]):\n",
    "        self.lemma = lemma\n",
    "        self.lang = lang\n",
    "        self.s = s\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.lang)+'_'+str(self.lemma)+'_'+str('-'.join(self.s))\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and self.s == other.s\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidix parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 921 ms\n"
     ]
    }
   ],
   "source": [
    "%time T = tree('https://raw.githubusercontent.com/apertium/apertium-eng-ita/master/apertium-eng-ita.eng-ita.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_word(word, lang):\n",
    "    s = word.findall('.//s')\n",
    "    s = [i.attrib['n'] for i in s]\n",
    "    return Word(word.text, lang, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_bidix (tree, l1, l2):\n",
    "    tree = tree.find('section')\n",
    "    if not tree:\n",
    "        print (l1, l2)\n",
    "    else:\n",
    "        for e in tree:\n",
    "            if 'n' in e.attrib:\n",
    "                side = e.attrib['n']\n",
    "            else:\n",
    "                side = None\n",
    "            p = e.find('p')\n",
    "            if p:\n",
    "                yield one_word(p.find('l'), l1), one_word(p.find('r'), l2), side\n",
    "            else:\n",
    "                try:\n",
    "                    i = e.find('i')\n",
    "                    yield one_word(i, l1), one_word(i, l2), side\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 882 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48880"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% time len(list(parse_bidix (T, 'bel','rus')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_bidix(G, T, l1, l2):\n",
    "    for word1, word2, side in parse_bidix (T, l1, l2):\n",
    "        if side == None:\n",
    "            G.add_edge(word1, word2)\n",
    "            G.add_edge(word2, word1)\n",
    "        elif side == 'LR':\n",
    "            G.add_edge(word1, word2)\n",
    "        elif side == 'RL':\n",
    "            G.add_edgr(word2, word1)\n",
    "        else:\n",
    "            print (side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetWithFilter(set):\n",
    "    def lemma(self, value):\n",
    "        return set(i for i in self if i.lemma == value)\n",
    "    #def pos(self, value):\n",
    "    #    return set(i for i in self if i.pos == value)\n",
    "    def lang(self, value):\n",
    "        return set(i for i in self if i.lang == value)\n",
    "    #def notlang(self, value):\n",
    "    #    return set(i for i in self if i.lang != value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictionaries(G, l1,l2):\n",
    "    l1 = l(l1)\n",
    "    l2 = l(l2)\n",
    "    d_l1 = SetWithFilter()\n",
    "    d_l2 = SetWithFilter()\n",
    "    for i in G.nodes():\n",
    "        if i.lang == l1:\n",
    "            d_l1.add(i)\n",
    "        elif i.lang == l2:\n",
    "            d_l2.add(i)\n",
    "    return d_l1, d_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma_search (G, lemma, d_l1, l2, cutoff):\n",
    "    lemmas = d_l1.lemma(lemma)\n",
    "    print (G.degree(lemmas))\n",
    "    print (lemmas)\n",
    "    results = {str(word):{} for word in lemmas}\n",
    "    for word in lemmas:\n",
    "        print(word, end='\\t')\n",
    "        s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "        print ('all: ', str(len(s)), end='\\t')\n",
    "        s = s.lang(l2)\n",
    "        print ('filtered: ', str(len(s)))\n",
    "        for translation in s:\n",
    "            t = list(nx.all_simple_paths(G, word, translation, cutoff=cutoff))\n",
    "            t = [len(i) for i in t]\n",
    "            t = Counter(t)\n",
    "            coef = 0\n",
    "            for i in t:\n",
    "                coef += exp(-t[i])\n",
    "            results[str(word)][str(translation)] = coef\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for i in results:\n",
    "        print ('\\n\\t\\t', i)\n",
    "        for j in sorted(results[i], key=results[i].get, reverse=True)[:7]:\n",
    "            print (j, results[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUS-FRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_relevant_languages('rus', 'fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-22 21:46:47,006 | INFO : Start\n",
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-fas.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "lit lav\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "2018-05-22 21:52:49,343 | INFO : Finish\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "logging.info('Start')\n",
    "for T, l1, l2 in load_chosen():\n",
    "    add_bidix(G, T, l1, l2)\n",
    "logging.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('graph.pkl','wb') as f:\n",
    "    pkl.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('graph.pkl','rb') as f:\n",
    "    G = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_l1, d_l2 = dictionaries(G, 'rus','fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_lemma (G, lemma, d_l1, l2):\n",
    "    lemmas = d_l1.lemma(lemma)\n",
    "    print (lemmas)\n",
    "    results = {str(word):{} for word in lemmas}\n",
    "    for word in lemmas:\n",
    "        print (word)\n",
    "        for cutoff in range(1, 8):\n",
    "            print (cutoff, end='\\t')\n",
    "            s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "            print ('all: ', str(len(s)), end='\\t')\n",
    "            s = s.lang(l2)\n",
    "            print ('filtered: ', str(len(s)))\n",
    "            if len(s)>150:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rus_собака_n-f-aa: 22, rus_собака_n-f: 2, rus_собака_n: 6}\n",
      "{rus_собака_n-f-aa, rus_собака_n-f, rus_собака_n}\n",
      "rus_собака_n-f-aa\tall:  2883\tfiltered:  37\n",
      "rus_собака_n-f\tall:  239\tfiltered:  3\n",
      "rus_собака_n\tall:  571\tfiltered:  15\n",
      "\n",
      "\t\t rus_собака_n-f-aa\n",
      "fra_chien_n-GD 0.4180019721672088\n",
      "fra_chien_n 0.36821490379934485\n",
      "fra_chien_n-m 0.3679248411012048\n",
      "fra_docteur_n 0.36787944117144233\n",
      "fra_docteur_n-GD 0.36787944117144233\n",
      "fra_sport_n-m 0.36787944117144233\n",
      "fra_compagnon_n 0.36787944117144233\n",
      "\n",
      "\t\t rus_собака_n-f\n",
      "fra_chien_n-GD 0.503214724408055\n",
      "fra_chien_n 0.36879132313699686\n",
      "fra_chien_n-m 0.36787944117144233\n",
      "\n",
      "\t\t rus_собака_n\n",
      "fra_chien_n-m 0.503214724408055\n",
      "fra_chien_n 0.41767265375165963\n",
      "fra_colimaçon_n-m 0.4176665095393063\n",
      "fra_limaçon_n-m 0.4176665095393063\n",
      "fra_chien_n-GD 0.4176665095393063\n",
      "fra_arobace_n-f 0.36787944117144233\n",
      "fra_but_n-m 0.36787944117144233\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'собака', d_l1, 'fra', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rus_поле_n: 6, rus_поле_n-nt: 2, rus_поле_n-nt-nn-pl: 2, rus_поле_n-nt-nn: 26}\n",
      "{rus_поле_n, rus_поле_n-nt, rus_поле_n-nt-nn-pl, rus_поле_n-nt-nn}\n",
      "rus_поле_n\tall:  278\tfiltered:  7\n",
      "rus_поле_n-nt\tall:  144\tfiltered:  2\n",
      "rus_поле_n-nt-nn-pl\tall:  3\tfiltered:  0\n",
      "rus_поле_n-nt-nn\tall:  1504\tfiltered:  11\n",
      "\n",
      "\t\t rus_поле_n\n",
      "fra_camp_n-m 0.7357588823428847\n",
      "fra_champ_n-m 0.7357588823428847\n",
      "fra_marge_n-m 0.7357588823428847\n",
      "fra_plantation_n-f 0.7357588823428847\n",
      "fra_marge_n-f 0.36787944117144233\n",
      "fra_rive_n-f 0.049787068367863944\n",
      "fra_berge_n-f 0.049787068367863944\n",
      "\n",
      "\t\t rus_поле_n-nt\n",
      "fra_camp_n-m 0.36787944117144233\n",
      "fra_champ_n-m 0.36787944117144233\n",
      "\n",
      "\t\t rus_поле_n-nt-nn-pl\n",
      "\n",
      "\t\t rus_поле_n-nt-nn\n",
      "fra_camp_n-m 0.3746173881705278\n",
      "fra_champ_n-m 0.3746173881705278\n",
      "fra_cadre_n 0.36787944117144233\n",
      "fra_camp_n 0.36787944117144233\n",
      "fra_patinoire_n-f 0.36787944117144233\n",
      "fra_champ_n 0.36787944117144233\n",
      "fra_domaine_n-m 0.36787944117144233\n",
      "Wall time: 689 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'поле', d_l1, 'fra', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{fra_serpent_n-m: 18, fra_serpent_n: 4, fra_serpent_n-m-ND: 2}\n",
      "{fra_serpent_n-m, fra_serpent_n, fra_serpent_n-m-ND}\n",
      "fra_serpent_n-m\tall:  725\tfiltered:  14\n",
      "fra_serpent_n\tall:  3\tfiltered:  0\n",
      "fra_serpent_n-m-ND\tall:  3\tfiltered:  0\n",
      "\n",
      "\t\t fra_serpent_n-m\n",
      "rus_змея_n 0.41768321124009655\n",
      "rus_змей_n 0.41768321124009655\n",
      "rus_змейка_n-f-nn 0.3861950800601765\n",
      "rus_змея_n-f-aa 0.3746173889287838\n",
      "rus_уж_n 0.3746173881705278\n",
      "rus_змей_n-m-aa 0.36879132313699686\n",
      "rus_гадюка_n-f-aa 0.36787944117144233\n",
      "\n",
      "\t\t fra_serpent_n\n",
      "\n",
      "\t\t fra_serpent_n-m-ND\n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'serpent', d_l2, 'rus', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{fra_enfant_n-m: 10, fra_enfant_n: 8, fra_enfant_n-n: 2, fra_enfant_n-mf-pl: 8, fra_enfant_n-m-ND: 2, fra_enfant_n-mf: 30, fra_enfant_n-mf-ND: 4, fra_enfant_n-mf-sg: 2}\n",
      "{fra_enfant_n-m, fra_enfant_n, fra_enfant_n-n, fra_enfant_n-mf-pl, fra_enfant_n-m-ND, fra_enfant_n-mf, fra_enfant_n-mf-ND, fra_enfant_n-mf-sg}\n",
      "fra_enfant_n-m\tall:  852\tfiltered:  19\n",
      "fra_enfant_n\tall:  782\tfiltered:  38\n",
      "fra_enfant_n-n\tall:  833\tfiltered:  17\n",
      "fra_enfant_n-mf-pl\tall:  45\tfiltered:  0\n",
      "fra_enfant_n-m-ND\tall:  32\tfiltered:  0\n",
      "fra_enfant_n-mf\tall:  6576\tfiltered:  88\n",
      "fra_enfant_n-mf-ND\tall:  586\tfiltered:  8\n",
      "fra_enfant_n-mf-sg\tall:  8\tfiltered:  0\n",
      "\n",
      "\t\t fra_enfant_n-m\n",
      "rus_мальчик_n-m-aa 0.3746173881705278\n",
      "rus_девочка_n-f-aa 0.3746173881705278\n",
      "rus_мадемуазель_n 0.36787944117144233\n",
      "rus_барышня_n 0.36787944117144233\n",
      "rus_паренек_n-m-aa 0.36787944117144233\n",
      "rus_сын_n-m-aa 0.36787944117144233\n",
      "rus_ребёнок_n 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n\n",
      "rus_мальчик_n 0.7357588823428847\n",
      "rus_ребенок_n-m-aa 0.503214724408055\n",
      "rus_младенец_n-m-aa 0.36821490379934485\n",
      "rus_чадо_n 0.36787944117144233\n",
      "rus_зрачок_n 0.36787944117144233\n",
      "rus_побочный сын_n 0.36787944117144233\n",
      "rus_малыш_n 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n-n\n",
      "rus_девочка_n-f-aa 0.4176665095393063\n",
      "rus_мальчик_n-m-aa 0.36879132313699686\n",
      "rus_мадемуазель_n 0.36787944117144233\n",
      "rus_барышня_n 0.36787944117144233\n",
      "rus_паренек_n-m-aa 0.36787944117144233\n",
      "rus_сын_n-m-aa 0.36787944117144233\n",
      "rus_юноша_n-m-aa 0.36787944117144233\n",
      "\n",
      "\t\t fra_enfant_n-mf-pl\n",
      "\n",
      "\t\t fra_enfant_n-m-ND\n",
      "\n",
      "\t\t fra_enfant_n-mf\n",
      "rus_барышня_n 0.503214724408055\n",
      "rus_незамужняя девица_n 0.503214724408055\n",
      "rus_мадемуазель_n 0.503214724408055\n",
      "rus_козленок_n-m-aa 0.503214724408055\n",
      "rus_грудной ребёнок_n 0.4176665095393063\n",
      "rus_ребёнок_n 0.38621178176096677\n",
      "rus_девка_n-f-aa 0.3861950800601765\n",
      "\n",
      "\t\t fra_enfant_n-mf-ND\n",
      "rus_ребёнок_n 0.1353352832366127\n",
      "rus_мальчик_n-m-aa 0.1353352832366127\n",
      "rus_девочка_n-f-aa 0.1353352832366127\n",
      "rus_младенец_n-m-aa 0.1353352832366127\n",
      "rus_дитя_n 0.1353352832366127\n",
      "rus_ребенок_n-m-aa 0.01831563888873418\n",
      "rus_ребёнок_n-m-aa 0.01831563888873418\n",
      "\n",
      "\t\t fra_enfant_n-mf-sg\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%time print_results(lemma_search (G, 'enfant', d_l2, 'rus', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra_enfant_n-mf\n",
      "fra_enfant_n-m\n",
      "fra_enfant_n\n",
      "fra_enfant_n-mf-ND\n",
      "fra_enfant_n-m-ND\n",
      "fra_enfant_n-mf-pl\n",
      "fra_enfant_n-mf-sg\n",
      "fra_enfant_n-n\n"
     ]
    }
   ],
   "source": [
    "for i in G.nodes():\n",
    "    if i.lemma == 'enfant':\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben_prpers_prn-p3-infml-aa-mf-sg-gen\n",
      "cym_rhywun_prn-tn-m-sg-tn-m-sg\n",
      "kaz_сіз_prn-pers-p2-sg-frm-gen-subst-nom\n",
      "eng_you're_prn-subj-p2-mf-sp-vbser-pres\n",
      "sco_ye're_prn-subj-p2-mf-sp-vbser-pres\n",
      "fin_sama_adj-pos-sg-ess-n-sg-ess\n",
      "hbs_na_pr-acc-prn-pers-clt-p3-m-sg-acc\n",
      "hin_वह_prn-dem-p3-mf-sg-dst-nom\n",
      "hin_वह_prn-dem-p3-mf-pl-dst-nom\n",
      "ita_Milà_np-cog-cog-cog-cog-mf-sp\n"
     ]
    }
   ],
   "source": [
    "for node in G.nodes():\n",
    "    if len(node.s) > 6:\n",
    "        print (node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in d_l1:\n",
    "    if i.lemma not in d:\n",
    "        d[i.lemma] = set()\n",
    "    d[i.lemma].add('_'.join(i.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17975050961623681\n"
     ]
    }
   ],
   "source": [
    "a = [' | '.join(list(sorted(d[i]))) for i in d if len(d[i])>1]\n",
    "print(len(a)/len(d_l1))\n",
    "a = Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n | n_m_nn 2841\n",
      "n | n_f_nn 2549\n",
      "n | n_m_aa 1178\n",
      "adj_sint | n 1149\n",
      "n | n_nt_nn 921\n",
      "adj | adj_sint | n 586\n",
      "adj | adj_sint 382\n",
      "n | vblex_perf | vblex_perf_tv 353\n",
      "n | vblex_perf_tv 344\n",
      "n | n_f | n_f_nn 287\n",
      "n | n_m | n_m_nn 265\n",
      "vblex_perf | vblex_perf_tv 251\n",
      "adv | n 236\n",
      "n | vblex_impf 218\n",
      "n | vblex_impf_tv 210\n",
      "n | n_f_aa 197\n",
      "n | vblex_impf | vblex_impf_tv 190\n",
      "adj | n 183\n",
      "vblex_impf | vblex_impf_tv 154\n",
      "n_m_aa | n_m_nn 132\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(a, key=a.get, reverse=True)[:20]:\n",
    "    print (i, a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in d_l2:\n",
    "    if i.lemma not in d:\n",
    "        d[i.lemma] = set()\n",
    "    d[i.lemma].add('_'.join(i.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = [d[i] for i in d if 'n' in d[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2980614543114543"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)/len([i.lemma for i in d_l2 if 'n' in i.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17001942380570761\n",
      "n | n_f 2496\n",
      "n | n_m 1651\n",
      "np | np_cog_mf_sp 811\n",
      "adj | n 583\n",
      "adj | adj_mf 386\n",
      "np | np_ant | np_ant_m_sg 330\n",
      "np | np_cog 325\n",
      "np | np_loc_f 311\n",
      "np | np_ant | np_ant_f_sg 288\n",
      "adj | n_m 257\n",
      "np | np_ant 230\n",
      "adj | adj_GD | adj_f | adj_m 193\n",
      "adj | n | n_m 172\n",
      "n_f | n_m 166\n",
      "np | np_ant_m_sg 118\n",
      "n | n_mf 117\n",
      "np_ant_f_sg | np_cog_mf_sp 98\n",
      "np | np_cog | np_cog_mf_sp 84\n",
      "adj | n | n_mf 83\n",
      "num | num_mf_sp 83\n"
     ]
    }
   ],
   "source": [
    "a = [' | '.join(list(sorted(d[i]))) for i in d if len(d[i])>1]\n",
    "print(len(a)/len(d_l2))\n",
    "a = Counter(a)\n",
    "for i in sorted(a, key=a.get, reverse=True)[:20]:\n",
    "    print (i, a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for every bidix\n",
    "- get relevant\n",
    "- try 4 max\n",
    "- exclude pair (skip)\n",
    "- for every word in actual bidix find best translation\n",
    "- compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg cat 35\n",
      "bel rus 35\n",
      "chv rus 25\n",
      "chv tat 25\n",
      "chv tur 25\n",
      "cos ita 36\n",
      "eus fin 30\n",
      "eus sme 30\n",
      "grn spa 32\n",
      "guc spa 32\n",
      "kir uzb 21\n",
      "kpv fin 27\n",
      "krl olo 26\n",
      "liv fin 26\n",
      "mrj fin 26\n",
      "myv fin 26\n",
      "oci cat 36\n",
      "oci fra 36\n",
      "oci spa 36\n",
      "olo fin 26\n",
      "quz spa 32\n",
      "rum ita 35\n",
      "scn spa 32\n",
      "udm kpv 36\n",
      "udm rus 36\n",
      "wel spa 32\n",
      "zho spa 32\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "    for fl in files :\n",
    "        pair = fl.replace('.dix', '').split('-')\n",
    "        one_comparison(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relevant (l1, l2):\n",
    "    G = nx.Graph()\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix', '').split('-')\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "    pair = [l(l1), l(l2)]\n",
    "    nodes = set()\n",
    "    i = 2\n",
    "    w = nx.single_source_shortest_path_length(G, pair[0], cutoff=i)\n",
    "    v = nx.single_source_shortest_path_length(G, pair[1], cutoff=i)\n",
    "    H = G.subgraph(w.keys())\n",
    "    H.remove_node(pair[0])\n",
    "    H2 = G.subgraph(v.keys())\n",
    "    H2.remove_node(pair[1])\n",
    "    if pair[1] in H.nodes():\n",
    "        v = nx.node_connected_component(H, pair[1])\n",
    "    else:\n",
    "        v = set()\n",
    "    if pair[0] in H2.nodes():\n",
    "        w = nx.node_connected_component(H, pair[1])\n",
    "    else:\n",
    "        w = set() \n",
    "    nodes = v & w | set([pair[0], pair[1]])\n",
    "    #if len(nodes) > 20 and len(nodes) < 40:\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word compare(G, d1, d2, d1_t, d2_t):\n",
    "    for word in d1:\n",
    "        if word in G.nodes():\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_comparison(l1_m, l2_m):\n",
    "    logging.info('Start\\t'+'{}\\t{}'.format(l1_m, l2_m))\n",
    "    nodes = relevant (l1_m, l2_m)\n",
    "    #print (nodes)\n",
    "    with open('language_list.csv','w', encoding='utf-8') as f:\n",
    "        for node in nodes:\n",
    "            f.write('{}\\t{}\\n'.format(4, node))\n",
    "    G = nx.DiGraph()\n",
    "    logging.info('Start loading')\n",
    "    for T, l1, l2 in load_chosen():\n",
    "        if not (l1 in [l1_m, l2_m] and l2 in [l1_m, l2_m]):\n",
    "            add_bidix(G, T, l1, l2)\n",
    "    d1_t, d2_t = dictionaries(G, l1_m, l2_m)\n",
    "    logging.info('Finish loading')\n",
    "    return G, d1_t, d2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-23 20:23:30,991 | INFO : Start\teng\trus\n",
      "2018-05-23 20:23:31,003 | INFO : Start loading\n",
      "ERROR:  epo-bul.dix\n",
      "ERROR:  epo-fas.dix\n",
      "ERROR:  epo-pol.dix\n",
      "ERROR:  fin-fra.dix\n",
      "lit lav\n",
      "ERROR:  pol-lav.dix\n",
      "ERROR:  sah-eng.dix\n",
      "2018-05-23 20:27:33,874 | INFO : Finish loading\n"
     ]
    }
   ],
   "source": [
    "G, d1_t, d2_t = one_comparison('eng', 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92083"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exact_search (G, word, lang, cutoff):\n",
    "    results = {}\n",
    "    if word in G:\n",
    "        s = SetWithFilter(nx.single_source_shortest_path_length(G, word, cutoff=cutoff))\n",
    "        #print ('all: ', str(len(s)), end='\\t')\n",
    "        s = s.lang(lang)\n",
    "        #print ('filtered: ', str(len(s)))\n",
    "        for translation in s:\n",
    "            t = list(nx.all_simple_paths(G, word, translation, cutoff=cutoff))\n",
    "            t = [len(i) for i in t]\n",
    "            t = Counter(t)\n",
    "            coef = 0\n",
    "            for i in t:\n",
    "                coef += exp(-t[i])\n",
    "            results[str(translation)] = coef\n",
    "        if results:\n",
    "            for j in sorted(results, key=results.get, reverse=True)[:7]:\n",
    "                #return [word, j, results[j]]\n",
    "                return [str(word), str(j), str(results[j])]\n",
    "        else:\n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bel_школа_n', 'rus_школа_n', '0.503214724408055']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_search (G, Word('школа','bel',['n']), 'rus', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2f4b298f8457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md1_t\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexact_search\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rus'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-dd8759c6f623>\u001b[0m in \u001b[0;36mexact_search\u001b[1;34m(G, word, lang, cutoff)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#print ('filtered: ', str(len(s)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtranslation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_simple_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\simple_paths.py\u001b[0m in \u001b[0;36m_all_simple_paths_graph\u001b[1;34m(G, source, target, cutoff)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvisited\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mvisited\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#len(visited) == cutoff:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\classes\\graph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \"\"\"\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6e9c110882d8>\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-6e9c110882d8>\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open ('test.csv', 'w', encoding='utf-8') as f:\n",
    "    for i in d1_t:\n",
    "        result = exact_search (G, i, 'rus', 4)\n",
    "        if result:\n",
    "            f.write('\\t'.join(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x1f6a9abe390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.parse('./dictionaries/arg-cat.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_language(lang):\n",
    "    dictionary = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for root, dirs, files in os.walk ('./dictionaries/'):\n",
    "        for fl in files :\n",
    "            pair = fl.replace('.dix','').split('-')\n",
    "            if lang in pair:\n",
    "                print (fl)\n",
    "                try:\n",
    "                    t = ET.parse(root+fl)\n",
    "                    for word1, word2, side in parse_bidix (t, pair[0], pair[1]):\n",
    "                        #word1 = str(word1)\n",
    "                        #word2 = str(word2)\n",
    "                        if lang == pair[0]:\n",
    "                            dictionary[word1.lemma]['-'.join(word1.s)] += 1\n",
    "                        else:\n",
    "                            dictionary[word2.lemma]['-'.join(word2.s)] += 1\n",
    "                except:\n",
    "                    pass\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'word': 1})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ava-rus.dix\n",
      "bel-rus.dix\n",
      "bul-rus.dix\n",
      "ces-rus.dix\n",
      "chv-rus.dix\n",
      "epo-rus.dix\n",
      "hbs-rus.dix\n",
      "isl-rus.dix\n",
      "kaz-rus.dix\n",
      "kom-rus.dix\n",
      "pol-rus.dix\n",
      "rus-eng.dix\n",
      "rus-ukr.dix\n",
      "tat-rus.dix\n",
      "udm-rus.dix\n",
      "Wall time: 5.29 s\n"
     ]
    }
   ],
   "source": [
    "%time dictionary = load_language('rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69366"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91724"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for i in dictionary:\n",
    "    k += len(dictionary[i])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f-aa': 11, 'n-f': 1, 'n': 3})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['собака']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f-aa': 11})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['кошка']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f': 1, 'n': 1, 'n-f-nn': 5})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['дверь']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'vblex-impf': 21, 'vblex-impf-iv': 9, 'n': 2, 'vblex-imperf': 4})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['идти']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get (w):\n",
    "    for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = set()\n",
    "for i in dictionary:\n",
    "    w = w | set(dictionary[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = set()\n",
    "for i in w:\n",
    "    v = v | set(i.split('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SPA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 17,\n",
       "             'n-f': 18,\n",
       "             'n-m-sg': 1,\n",
       "             'n-m-pl': 1,\n",
       "             'adj-mf': 7,\n",
       "             'n': 9,\n",
       "             'adj': 9,\n",
       "             'adj-mf-sg': 4,\n",
       "             'adj-mf-pl': 2,\n",
       "             'n-f-sg': 5})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n': 145, 'vblex': 7, 'n-ND': 3, 'np': 1, 'n-sg': 1, '': 1})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n': 81, 'vblex': 12, 'n-sg': 1})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['pen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 78\n",
      "n-ND 1\n",
      "n-sg 2\n",
      "vblex 5\n"
     ]
    }
   ],
   "source": [
    "word = 'gun'\n",
    "beginning = ''\n",
    "for key in sorted(dictionary[word]):\n",
    "    #if re.match('^'+beginning, key):\n",
    "    print(key, dictionary[word][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** FRA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-f': 12, 'n-f-ND': 1, 'n': 6})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['porte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-mf': 23,\n",
       "             'n-m': 8,\n",
       "             'np-ant': 1,\n",
       "             'adj': 1,\n",
       "             'n': 7,\n",
       "             'n-mf-ND': 2,\n",
       "             'n-m-ND': 1,\n",
       "             'n-mf-pl': 6,\n",
       "             'n-mf-sg': 1,\n",
       "             'n-n': 1})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['enfant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 60, 'n-m-ND': 3, 'n': 20, 'm': 1})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['coup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.load_language.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "            {'n-m': 20, 'm-sg': 1, 'n': 17, 'n-m-ND': 2})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['jour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in dictionary:\n",
    "    if len(dictionary[i]) > 5:\n",
    "        print (i, ' | '.join(dictionary[i].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
