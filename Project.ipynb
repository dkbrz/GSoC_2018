{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilingual dictionary enrichment via graph completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import na\n",
    "import pandas as pd\n",
    "lang_codes = pd.read_csv('./files/language-codes-full_csv.csv', na_values = 0)\n",
    "lang_codes = lang_codes[['alpha3-b','alpha2']]\n",
    "lang_codes = lang_codes.dropna()\n",
    "\n",
    "\n",
    "lang_codes = [{i[0]:i[1] for i in np.array(lang_codes)}, {i[1]:i[0] for i in np.array(lang_codes)}]\n",
    "\n",
    "with open ('./files/lang_codes.json', 'w') as f:\n",
    "    json.dump(lang_codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('./files/lang_codes.json', 'r') as f:\n",
    "    lang_codes = json.load(f)\n",
    "\n",
    "def l(lang, mode=3):\n",
    "    mode = mode % 2\n",
    "    if len(lang)==2:\n",
    "        if lang in lang_codes[mode]:\n",
    "            return lang_codes[mode][lang]\n",
    "        else:\n",
    "            return lang\n",
    "    else:\n",
    "        return lang\n",
    "l('tt', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git - not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import git\n",
    "\n",
    "def clone_folder(name='apertium-trunk', target='./data/'):\n",
    "    repo = git.Repo.clone_from('https://github.com/apertium/'+name+'/', target)\n",
    "    for i in git.objects.submodule.root.RootModule(repo).list_items(repo):\n",
    "        git.Repo.clone_from('https://github.com/apertium/'+i.name, './data/'+i.name)\n",
    "        logging.info(i.name)\n",
    "\n",
    "clone_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 3 hours to clone aprtium-trunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load user with login and password from secret file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "with open ('secure.json') as f:\n",
    "    SECRET = json.loads(f.read())\n",
    "\n",
    "github = Github(SECRET['USER'], SECRET['PASSWORD'])\n",
    "\n",
    "user = github.get_user('apertium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user.get_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generator ** : yield all repos that match name pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repo_names(user):\n",
    "    for repo in user.get_repos():\n",
    "        if re.match('apertium-[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?', repo.name):\n",
    "            yield repo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like heavy function. But I don't see any improvements yet, except for having certain repo for all bidix copies. But this one above is the most up-to-date. It filters not languages pair repos, it is needed not to look for bidix where it can't be. Function saves a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%time w = list(repo_names(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find bidix **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    bidix = repo.name+'.'+repo.name.replace('apertium-','')+'.dix'\n",
    "    for i in repo.get_dir_contents('/'):\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix', i.path):\n",
    "            return i.download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/apertium/apertium-afr-nld/master/apertium-afr-nld.afr-nld.dix'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bidix_url(github.get_repo(user.name+'/'+w[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed is ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check repos for bidixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apertium-en-lv\n",
      "apertium-est-nor\n",
      "apertium-ita-srd\n",
      "apertium-ky-en\n",
      "apertium-lex-tools\n",
      "apertium-on-github\n",
      "apertium-ru-cu\n",
      "apertium-sc-pt\n",
      "apertium-urd-pan\n"
     ]
    }
   ],
   "source": [
    "def download(user):\n",
    "    for repo_name in repo_names(user):\n",
    "        bidix = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if not bidix:\n",
    "            print (repo_name)\n",
    "\n",
    "download(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these repos do not have bidixes except for the last one. There are two of them. So that's strange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** XML reading ** : return xml tree object. Read file with request from github and return object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree(url):\n",
    "    response = requests.get(url)\n",
    "    return ET.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check bidixes, because errors occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download():\n",
    "    for repo_name in repo_names(user):\n",
    "        url = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if url:\n",
    "            lang = re.findall('\\.([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})\\.dix$', url)\n",
    "            l1, l2 = lang[0][0], lang[0][1]\n",
    "            try:\n",
    "                t = tree(url)\n",
    "            except:\n",
    "                print(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eo bg\n",
      "eo fa\n",
      "eo pl\n",
      "fin fra\n",
      "pl lv\n",
      "sah eng\n",
      "Wall time: 12min 6s\n"
     ]
    }
   ],
   "source": [
    "%time download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Errors **\n",
    "\n",
    "- eo-bg : strange header section with sdefs    ParseError: mismatched tag: line 10, column 4\n",
    "- eo-fa : same, looks like < sdef n=\"n\" > should be < sdef n=\"n\"/>\n",
    "- eo-pl : same\n",
    "- fin-fra : < !-- \\n {{{ Punctuatkion and stuff \\n {{{ puncts --> ParseError: not well-formed (invalid token): line 152, column 4\n",
    "- pl-lv : Possibly, not closed < alphabet > (dictionary) ParseError: mismatched tag: line 296, column 2\n",
    "- sah-eng : \" [< Russ. \" in text, this is parsed as tag : ParseError: not well-formed (invalid token): line 339, column 114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree('https://raw.githubusercontent.com/apertium/apertium-sah-eng/master/apertium-sah-eng.sah-eng.dix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all files (even without parsing) takes a lot of time (12 minutes on Windows). So to reduce time in case of gathering files instead of one folder on github we need to reduce number of languages we download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Only relevant for certain language pair **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are **164 ** pairs at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repos_for_pair(user, l1, l2, n=[2]):\n",
    "    logging.info('Start')\n",
    "    G = nx.DiGraph()\n",
    "    lg = (l(l1,3), l(l2,3))\n",
    "    for name in repo_names(user):\n",
    "        w = re.findall('.*?-([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})$', name)[0]\n",
    "        w = (l(w[0],3), l(w[1],3))\n",
    "        if w[0] == lg[0] or w[1] == lg[1]: G.add_edge(w[0],w[1])\n",
    "        elif w[0] == lg[1] or w[1] == lg[0]: G.add_edge(w[1],w[0])\n",
    "        else:\n",
    "            G.add_edge(w[0],w[1])\n",
    "            G.add_edge(w[1],w[0])\n",
    "    if (lg[0], lg[1]) in G.edges(): G.remove_edge(lg[0], lg[1])\n",
    "    if (lg[1], lg[0]) in G.edges(): G.remove_edge(lg[1], lg[0])\n",
    "    logging.info('Graph')\n",
    "    \n",
    "    for i in n:\n",
    "        w = nx.single_source_shortest_path_length(G, lg[0], cutoff=i)\n",
    "        v = nx.single_source_shortest_path_length(G, lg[1], cutoff=i)\n",
    "        nodes = list((set(w.keys())&set(w.keys()) )| set([lg[0],lg[1]]))\n",
    "        H = G.subgraph(nodes)\n",
    "        logging.info('Length: {}\\tNodes: {}'.format(i, len(nodes)))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 21:44:02,582 | INFO : Start\n",
      "2018-05-16 21:44:30,430 | INFO : Graph\n",
      "2018-05-16 21:44:30,430 | INFO : Length: 1\tNodes: 8\n",
      "2018-05-16 21:44:30,430 | INFO : Length: 2\tNodes: 70\n",
      "2018-05-16 21:44:30,447 | INFO : Length: 3\tNodes: 134\n",
      "2018-05-16 21:44:30,451 | INFO : Length: 4\tNodes: 145\n",
      "2018-05-16 21:44:30,455 | INFO : Length: 5\tNodes: 146\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%time G = get_repos_for_pair(user, 'tat', 'rus', list(range(1,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 10:14:52,693 | INFO : Start\n",
      "2018-05-16 10:15:18,908 | INFO : Graph\n",
      "2018-05-16 10:15:18,908 | INFO : Length: 1\tNodes: 4\n",
      "2018-05-16 10:15:18,908 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-16 10:15:18,922 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-16 10:15:18,924 | INFO : Length: 4\tNodes: 4\n",
      "2018-05-16 10:15:18,926 | INFO : Length: 5\tNodes: 4\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%time G = get_repos_for_pair(user, 'urd', 'hin',  list(range(1,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 10:15:18,937 | INFO : Start\n",
      "2018-05-16 10:15:45,703 | INFO : Graph\n",
      "2018-05-16 10:15:45,705 | INFO : Length: 1\tNodes: 25\n",
      "2018-05-16 10:15:45,707 | INFO : Length: 2\tNodes: 104\n",
      "2018-05-16 10:15:45,710 | INFO : Length: 3\tNodes: 137\n",
      "2018-05-16 10:15:45,713 | INFO : Length: 4\tNodes: 140\n",
      "2018-05-16 10:15:45,716 | INFO : Length: 5\tNodes: 140\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%time G = get_repos_for_pair(user, 'epo', 'spa', list(range(1,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 10:19:23,912 | INFO : Start\n",
      "2018-05-16 10:19:49,860 | INFO : Graph\n",
      "2018-05-16 10:19:49,860 | INFO : Length: 1\tNodes: 4\n",
      "2018-05-16 10:19:49,860 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-16 10:19:49,865 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-16 10:19:49,867 | INFO : Length: 4\tNodes: 4\n",
      "2018-05-16 10:19:49,870 | INFO : Length: 5\tNodes: 4\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%time G = get_repos_for_pair(user, 'zul', 'hin',  list(range(1,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 10:21:21,185 | INFO : Start\n",
      "2018-05-16 10:21:45,652 | INFO : Graph\n",
      "2018-05-16 10:21:45,652 | INFO : Length: 1\tNodes: 14\n",
      "2018-05-16 10:21:45,652 | INFO : Length: 2\tNodes: 85\n",
      "2018-05-16 10:21:45,667 | INFO : Length: 3\tNodes: 142\n",
      "2018-05-16 10:21:45,670 | INFO : Length: 4\tNodes: 146\n",
      "2018-05-16 10:21:45,672 | INFO : Length: 5\tNodes: 146\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%time G = get_repos_for_pair(user, 'kaz', 'tur',  list(range(1,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Final loading **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repos_for_pair(user, l1, l2, n=[2]):\n",
    "    logging.info('Start')\n",
    "    pair_list = []\n",
    "    G = nx.DiGraph()\n",
    "    lg = (l(l1,3), l(l2,3))\n",
    "    for name in repo_names(user):\n",
    "        pair_list.append(name)\n",
    "        w = re.findall('.*?-([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})$', name)[0]\n",
    "        w = (l(w[0],3), l(w[1],3))\n",
    "        if w[0] == lg[0] or w[1] == lg[1]: G.add_edge(w[0],w[1])\n",
    "        elif w[0] == lg[1] or w[1] == lg[0]: G.add_edge(w[1],w[0])\n",
    "        else:\n",
    "            G.add_edge(w[0],w[1])\n",
    "            G.add_edge(w[1],w[0])\n",
    "    if (lg[0], lg[1]) in G.edges():\n",
    "        G.remove_edge(lg[0], lg[1])\n",
    "    if (lg[1], lg[0]) in G.edges():\n",
    "        G.remove_edge(lg[1], lg[0])\n",
    "    logging.info('Built graph')\n",
    "    \n",
    "    for i in n:\n",
    "        w = nx.single_source_shortest_path_length(G, lg[0], cutoff=i)\n",
    "        v = nx.single_source_shortest_path_length(G, lg[1], cutoff=i)\n",
    "        nodes = list((set(w.keys())&set(w.keys()) )| set([lg[0],lg[1]]))\n",
    "        H = G.subgraph(nodes)\n",
    "        logging.info('Length: {}\\tNodes: {}'.format(i, len(nodes)))\n",
    "    \n",
    "    number = int(input('What graph to choose?\\t'))\n",
    "    w = nx.single_source_shortest_path_length(G, lg[0], cutoff=number)\n",
    "    v = nx.single_source_shortest_path_length(G, lg[1], cutoff=number)\n",
    "    nodes = list((set(w.keys())&set(w.keys()) )| set([lg[0],lg[1]]))\n",
    "    return set(nodes), pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_names(nodes:set, pair_list):\n",
    "    for repo in pair_list:\n",
    "        langs = re.findall('apertium-(.*?)-(.*?)$', repo)[0]\n",
    "        if l(langs[0]) in nodes and l(langs[1]) in nodes:\n",
    "            yield repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_language_pair_support(user, l1, l2, n=[2]):\n",
    "    nodes, pair_list = get_repos_for_pair(user, l1, l2, n)\n",
    "    logging.info('Started loading')\n",
    "    for repo_name in filter_names(nodes, pair_list):\n",
    "        #print(user.name+'/'+repo_name)\n",
    "        url = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if url:\n",
    "            lang = re.findall('.*?\\.([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})\\.dix$', url)\n",
    "            if lang:\n",
    "                l1, l2 = lang[0][0], lang[0][1]\n",
    "                try:\n",
    "                    t = tree(url)\n",
    "                    yield t\n",
    "                except:\n",
    "                    #print(l1, l2)\n",
    "                    pass\n",
    "            else:\n",
    "                print (url)\n",
    "    logging.info('Finished')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 22:30:22,741 | INFO : Start\n",
      "2018-05-16 22:30:48,962 | INFO : Built graph\n",
      "2018-05-16 22:30:48,977 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-16 22:30:48,977 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-16 22:30:48,981 | INFO : Length: 4\tNodes: 4\n",
      "What graph to choose?\t2\n",
      "2018-05-16 22:30:50,981 | INFO : Started loading\n",
      "2018-05-16 22:30:59,286 | INFO : Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Element 'dictionary' at 0x000001CCDE33CEA8>,\n",
       " <Element 'dictionary' at 0x000001CCDE33CA98>,\n",
       " <Element 'dictionary' at 0x000001CCDE33CEF8>,\n",
       " <Element 'dictionary' at 0x000001CCDF85AE58>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'urd','hin', n=[2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 22:36:52,278 | INFO : Start\n",
      "2018-05-16 22:37:20,187 | INFO : Built graph\n",
      "2018-05-16 22:37:20,187 | INFO : Length: 2\tNodes: 70\n",
      "2018-05-16 22:37:20,187 | INFO : Length: 3\tNodes: 134\n",
      "2018-05-16 22:37:20,196 | INFO : Length: 4\tNodes: 145\n",
      "What graph to choose?\t4\n",
      "2018-05-16 22:37:22,564 | INFO : Started loading\n",
      "eo bg\n",
      "eo fa\n",
      "eo pl\n",
      "fin fra\n",
      "pl lv\n",
      "sah eng\n",
      "2018-05-16 22:51:21,585 | INFO : Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Element 'dictionary' at 0x000001CCDF868188>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'tat','rus', n=[2,3,4]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('apertium-ur-pa.ur-pa.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContentFile(path=\".gitattributes\"),\n",
       " ContentFile(path=\".gitignore\"),\n",
       " ContentFile(path=\"ACKNOWLEDGEMENTS.txt\"),\n",
       " ContentFile(path=\"AUTHORS\"),\n",
       " ContentFile(path=\"Makefile\"),\n",
       " ContentFile(path=\"apertium-as-hi.as-hi.dix\"),\n",
       " ContentFile(path=\"apertium-as-hi.as-hi.t1x\"),\n",
       " ContentFile(path=\"apertium-as-hi.as.dix\"),\n",
       " ContentFile(path=\"apertium-as-hi.hi.dix\"),\n",
       " ContentFile(path=\"as-hi.prob\"),\n",
       " ContentFile(path=\"hi-as.prob\"),\n",
       " ContentFile(path=\"modes.xml\"),\n",
       " ContentFile(path=\"new\")]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github.get_repo('apertium/apertium-as-hi').get_dir_contents('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    #print(repo)\n",
    "    for i in sorted(repo.get_dir_contents('/'), key = lambda x: (len(x.path), 1000-ord(('   '+x.path)[-3])), reverse=True):\n",
    "        #print (i.path)\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix', i.path):\n",
    "            return i.download_url\n",
    "        elif len(i.path) < 23:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 23:38:04,132 | INFO : Start\n",
      "2018-05-16 23:38:30,729 | INFO : Built graph\n",
      "2018-05-16 23:38:30,744 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-16 23:38:30,744 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-16 23:38:30,744 | INFO : Length: 4\tNodes: 4\n",
      "What graph to choose?\t4\n",
      "2018-05-16 23:38:40,387 | INFO : Started loading\n",
      "2018-05-16 23:38:45,419 | INFO : Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Element 'dictionary' at 0x00000283861D7F48>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'urd','hin', n=[2,3,4]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContentFile(path=\".gitattributes\"),\n",
       " ContentFile(path=\".gitignore\"),\n",
       " ContentFile(path=\"AUTHORS\"),\n",
       " ContentFile(path=\"COPYING\"),\n",
       " ContentFile(path=\"ChangeLog\"),\n",
       " ContentFile(path=\"Makefile.am\"),\n",
       " ContentFile(path=\"NEWS\"),\n",
       " ContentFile(path=\"README\"),\n",
       " ContentFile(path=\"apertium-arg-cat.arg-cat.dix\"),\n",
       " ContentFile(path=\"apertium-arg-cat.arg-cat.lrx\"),\n",
       " ContentFile(path=\"apertium-arg-cat.arg-cat.t1x\"),\n",
       " ContentFile(path=\"apertium-arg-cat.cat-arg.lrx\"),\n",
       " ContentFile(path=\"apertium-arg-cat.cat-arg.t1x\"),\n",
       " ContentFile(path=\"autogen.sh\"),\n",
       " ContentFile(path=\"configure.ac\"),\n",
       " ContentFile(path=\"dev\"),\n",
       " ContentFile(path=\"genvrdix.py\"),\n",
       " ContentFile(path=\"modes.xml\"),\n",
       " ContentFile(path=\"t\"),\n",
       " ContentFile(path=\"texts\")]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github.get_repo('Apertium/apertium-arg-cat').get_dir_contents('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentFile(path=\"apertium-arg-cat.arg-cat.dix\")\n",
      "ContentFile(path=\"apertium-arg-cat.arg-cat.lrx\")\n",
      "ContentFile(path=\"apertium-arg-cat.cat-arg.lrx\")\n",
      "ContentFile(path=\"apertium-arg-cat.arg-cat.t1x\")\n",
      "ContentFile(path=\"apertium-arg-cat.cat-arg.t1x\")\n",
      "ContentFile(path=\".gitattributes\")\n",
      "ContentFile(path=\"configure.ac\")\n",
      "ContentFile(path=\"Makefile.am\")\n",
      "ContentFile(path=\"genvrdix.py\")\n",
      "ContentFile(path=\"autogen.sh\")\n",
      "ContentFile(path=\".gitignore\")\n",
      "ContentFile(path=\"ChangeLog\")\n",
      "ContentFile(path=\"modes.xml\")\n",
      "ContentFile(path=\"COPYING\")\n",
      "ContentFile(path=\"AUTHORS\")\n",
      "ContentFile(path=\"README\")\n",
      "ContentFile(path=\"texts\")\n",
      "ContentFile(path=\"NEWS\")\n",
      "ContentFile(path=\"dev\")\n",
      "ContentFile(path=\"t\")\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(github.get_repo('Apertium/apertium-arg-cat').get_dir_contents('/'),key = lambda x: (len(x.path), 1000-ord(('   '+x.path)[-3])), reverse=True):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 23:58:17,225 | INFO : Start\n",
      "2018-05-16 23:58:47,891 | INFO : Built graph\n",
      "2018-05-16 23:58:47,891 | INFO : Length: 2\tNodes: 70\n",
      "2018-05-16 23:58:47,891 | INFO : Length: 3\tNodes: 134\n",
      "2018-05-16 23:58:47,905 | INFO : Length: 4\tNodes: 145\n",
      "What graph to choose?\t4\n",
      "2018-05-16 23:58:52,678 | INFO : Started loading\n",
      "https://raw.githubusercontent.com/apertium/apertium-eo-cs/master/apertium-eo-cs.eo-cs.dix2\n",
      "https://raw.githubusercontent.com/apertium/apertium-hbs-slv/master/apertium-hbs-slv.hbs-slv.dix.old\n"
     ]
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'tat','rus', n=[2,3,4]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'dictionary' at 0x000001CCDB4114A8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree('https://raw.githubusercontent.com/apertium/apertium-urd-hin/master/apertium-urd-hin.urd-hin.dix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Word **\n",
    "\n",
    "- lemma : lemma\n",
    "- lang : language\n",
    "- pos : part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, pos, add=[]):\n",
    "        self.lemma = lemma\n",
    "        self.lang = lang\n",
    "        self.pos = pos\n",
    "        self.add = add\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (str(self.lang)+'_'+str(self.lemma)+'_'+str(self.pos))+'_'+str('-'.join(self.add))\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and self.pos == other.pos\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
