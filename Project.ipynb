{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilingual dictionary enrichment via graph completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import na\n",
    "import pandas as pd\n",
    "lang_codes = pd.read_csv('./files/language-codes-full_csv.csv', na_values = 0)\n",
    "lang_codes = lang_codes[['alpha3-b','alpha2']]\n",
    "lang_codes = lang_codes.dropna()\n",
    "\n",
    "\n",
    "lang_codes = [{i[0]:i[1] for i in np.array(lang_codes)}, {i[1]:i[0] for i in np.array(lang_codes)}]\n",
    "\n",
    "with open ('./files/lang_codes.json', 'w') as f:\n",
    "    json.dump(lang_codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tat'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('./files/lang_codes.json', 'r') as f:\n",
    "    lang_codes = json.load(f)\n",
    "\n",
    "def l(lang, mode=3):\n",
    "    mode = mode % 2\n",
    "    if len(lang)==2:\n",
    "        if lang in lang_codes[mode]:\n",
    "            return lang_codes[mode][lang]\n",
    "        else:\n",
    "            return lang\n",
    "    else:\n",
    "        return lang\n",
    "l('tt', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git - not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import git\n",
    "\n",
    "def clone_folder(name='apertium-trunk', target='./data/'):\n",
    "    repo = git.Repo.clone_from('https://github.com/apertium/'+name+'/', target)\n",
    "    for i in git.objects.submodule.root.RootModule(repo).list_items(repo):\n",
    "        git.Repo.clone_from('https://github.com/apertium/'+i.name, './data/'+i.name)\n",
    "        logging.info(i.name)\n",
    "\n",
    "clone_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took 3 hours to clone aprtium-trunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyGithub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load user with login and password from secret file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "with open ('secure.json') as f:\n",
    "    SECRET = json.loads(f.read())\n",
    "\n",
    "github = Github(SECRET['USER'], SECRET['PASSWORD'])\n",
    "\n",
    "user = github.get_user('apertium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user.get_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generator ** : yield all repos that match name pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repo_names(user):\n",
    "    for repo in user.get_repos():\n",
    "        if re.match('apertium-[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?', repo.name):\n",
    "            yield repo.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like heavy function. But I don't see any improvements yet, except for having certain repo for all bidix copies. But this one above is the most up-to-date. It filters not languages pair repos, it is needed not to look for bidix where it can't be. Function saves a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%time w = list(repo_names(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find bidix **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    bidix = repo.name+'.'+repo.name.replace('apertium-','')+'.dix'\n",
    "    for i in repo.get_dir_contents('/'):\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix', i.path):\n",
    "            return i.download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/apertium/apertium-cat-srd/master/apertium-cat-srd.cat-srd.dix'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bidix_url(github.get_repo(user.name+'/'+w[22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bidix_url(repo):\n",
    "    for i in sorted(repo.get_dir_contents('/'), key = lambda x: (len(x.path), 1000-ord(('   '+x.path)[-3])), reverse=True):\n",
    "        if re.match('apertium-.*?\\.[a-z]{2,3}(_[a-zA-Z]{2,3})?-[a-z]{2,3}(_[a-zA-Z]{2,3})?.dix$', i.path):\n",
    "            return i.download_url\n",
    "        elif len(i.path) < 23:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 709 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/apertium/apertium-cat-srd/master/apertium-cat-srd.cat-srd.dix'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bidix_url(github.get_repo(user.name+'/'+w[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed is ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check repos for bidixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apertium-en-lv\n",
      "apertium-est-nor\n",
      "apertium-ita-srd\n",
      "apertium-ky-en\n",
      "apertium-lex-tools\n",
      "apertium-on-github\n",
      "apertium-ru-cu\n",
      "apertium-sc-pt\n",
      "apertium-urd-pan\n"
     ]
    }
   ],
   "source": [
    "def download(user):\n",
    "    for repo_name in repo_names(user):\n",
    "        bidix = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if not bidix:\n",
    "            print (repo_name)\n",
    "\n",
    "download(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these repos do not have bidixes except for the last one. There are two of them. So that's strange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** XML reading ** : return xml tree object. Read file with request from github and return object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree(url):\n",
    "    response = requests.get(url)\n",
    "    return ET.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check bidixes, because errors occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Errors **\n",
    "\n",
    "- eo-bg : strange header section with sdefs    ParseError: mismatched tag: line 10, column 4\n",
    "- eo-fa : same, looks like < sdef n=\"n\" > should be < sdef n=\"n\"/>\n",
    "- eo-pl : same\n",
    "- fin-fra : < !-- \\n {{{ Punctuatkion and stuff \\n {{{ puncts --> ParseError: not well-formed (invalid token): line 152, column 4\n",
    "- pl-lv : Possibly, not closed < alphabet > (dictionary) ParseError: mismatched tag: line 296, column 2\n",
    "- sah-eng : \" [< Russ. \" in text, this is parsed as tag : ParseError: not well-formed (invalid token): line 339, column 114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree('https://raw.githubusercontent.com/apertium/apertium-sah-eng/master/apertium-sah-eng.sah-eng.dix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all files (even without parsing) takes a lot of time (12 minutes on Windows). So to reduce time in case of gathering files instead of one folder on github we need to reduce number of languages we download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Only relevant for certain language pair **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There are **164 ** pairs at this moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repos_for_pair(user, l1, l2, n=[2]):\n",
    "    logging.info('Start')\n",
    "    G = nx.DiGraph()\n",
    "    lg = (l(l1,3), l(l2,3))\n",
    "    pair_list = []\n",
    "    for name in repo_names(user):\n",
    "        pair_list.append(name)\n",
    "        w = re.findall('.*?-([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})$', name)[0]\n",
    "        w = (l(w[0],3), l(w[1],3))\n",
    "        if w[0] == lg[0] or w[1] == lg[1]: G.add_edge(w[0],w[1])\n",
    "        elif w[0] == lg[1] or w[1] == lg[0]: G.add_edge(w[1],w[0])\n",
    "        else:\n",
    "            G.add_edge(w[0],w[1])\n",
    "            G.add_edge(w[1],w[0])\n",
    "    if (lg[0], lg[1]) in G.edges(): G.remove_edge(lg[0], lg[1])\n",
    "    if (lg[1], lg[0]) in G.edges(): G.remove_edge(lg[1], lg[0])\n",
    "    logging.info('Graph')\n",
    "    \n",
    "    for i in n:\n",
    "        w = nx.single_source_shortest_path_length(G, lg[0], cutoff=i)\n",
    "        v = nx.single_source_shortest_path_length(G, lg[1], cutoff=i)\n",
    "        nodes = list((set(w.keys())&set(w.keys()) )| set([lg[0],lg[1]]))\n",
    "        H = G.subgraph(nodes)\n",
    "        logging.info('Length: {}\\tNodes: {}'.format(i, len(nodes)))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Final loading **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_repos_for_pair(user, l1, l2, n=[2]):\n",
    "    logging.info('Start')\n",
    "    pair_list = []\n",
    "    G = nx.Graph()\n",
    "    lg = (l(l1,3), l(l2,3))\n",
    "    for name in repo_names(user):\n",
    "        pair_list.append(name)\n",
    "        w = [l(i,3) for i in re.findall('.*?-([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})$', name)[0]]\n",
    "        G.add_edge(w[0],w[1])\n",
    "    logging.info('Built graph')\n",
    "    \n",
    "    for i in n:\n",
    "        w = nx.single_source_shortest_path_length(G, lg[0], cutoff=i)\n",
    "        v = nx.single_source_shortest_path_length(G, lg[1], cutoff=i)\n",
    "        H = G.subgraph(w.keys())\n",
    "        H.remove_node(lg[0])\n",
    "        H2 = G.subgraph(v.keys())\n",
    "        H2.remove_node(lg[1])\n",
    "        nodes = set(nx.node_connected_component(H, lg[1])) & set(nx.node_connected_component(H2, lg[0])) | set([lg[0], lg[1]])\n",
    "        logging.info('Length: {}\\tNodes: {}'.format(i, len(nodes)))\n",
    "        \n",
    "    i = int(input('Choose max halfway: '))\n",
    "    w = nx.single_source_shortest_path_length(G, lg[0], cutoff=i)\n",
    "    v = nx.single_source_shortest_path_length(G, lg[1], cutoff=i)\n",
    "    H = G.subgraph(w.keys())\n",
    "    H.remove_node(lg[0])\n",
    "    H2 = G.subgraph(v.keys())\n",
    "    H2.remove_node(lg[1])\n",
    "    nodes = set(nx.node_connected_component(H, lg[1])) & set(nx.node_connected_component(H2, lg[0]))| set([lg[0], lg[1]])\n",
    "    return set(nodes), pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_names(nodes:set, pair_list):\n",
    "    for repo in pair_list:\n",
    "        langs = re.findall('apertium-(.*?)-(.*?)$', repo)[0]\n",
    "        if l(langs[0]) in nodes and l(langs[1]) in nodes:\n",
    "            yield repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_language_pair_support(user, l1, l2, n=[2]):\n",
    "    nodes, pair_list = get_repos_for_pair(user, l1, l2, n)\n",
    "    logging.info('Started loading')\n",
    "    for repo_name in filter_names(nodes, pair_list):\n",
    "        logging.info(repo_name)\n",
    "        url = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if url:\n",
    "            lang = re.findall('.*?\\.([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})\\.dix$', url)\n",
    "            if lang:\n",
    "                l1, l2 = lang[0][0], lang[0][1]\n",
    "                try:\n",
    "                    t = tree(url)\n",
    "                    yield t\n",
    "                except:\n",
    "                    #print(l1, l2)\n",
    "                    pass\n",
    "            else:\n",
    "                print (url)\n",
    "    logging.info('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 17:39:43,298 | INFO : Start\n",
      "2018-05-17 17:40:09,223 | INFO : Built graph\n",
      "2018-05-17 17:40:09,223 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-17 17:40:09,231 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-17 17:40:09,234 | INFO : Length: 4\tNodes: 4\n",
      "Choose max halfway: 4\n",
      "2018-05-17 17:40:18,115 | INFO : Started loading\n",
      "2018-05-17 17:40:23,386 | INFO : Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Element 'dictionary' at 0x0000017B022DD1D8>,\n",
       " <Element 'dictionary' at 0x0000017B7EC54548>,\n",
       " <Element 'dictionary' at 0x0000017B009780E8>,\n",
       " <Element 'dictionary' at 0x0000017B00E77188>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'urd','hin', n=[2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 17:40:27,545 | INFO : Start\n",
      "2018-05-17 17:41:00,468 | INFO : Built graph\n",
      "2018-05-17 17:41:00,468 | INFO : Length: 2\tNodes: 4\n",
      "2018-05-17 17:41:00,468 | INFO : Length: 3\tNodes: 4\n",
      "2018-05-17 17:41:00,479 | INFO : Length: 4\tNodes: 4\n",
      "Choose max halfway: 4\n",
      "2018-05-17 17:41:03,828 | INFO : Started loading\n",
      "2018-05-17 17:41:08,687 | INFO : Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Element 'dictionary' at 0x0000017B0083ADB8>,\n",
       " <Element 'dictionary' at 0x0000017B047EAEF8>,\n",
       " <Element 'dictionary' at 0x0000017B03527D68>,\n",
       " <Element 'dictionary' at 0x0000017B05573F48>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(download_language_pair_support(user, 'hin','urd', n=[2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_all(user):\n",
    "    logging.info('Start')\n",
    "    for repo_name in repo_names(user):\n",
    "        url = bidix_url(github.get_repo(user.name+'/'+repo_name))\n",
    "        if url:\n",
    "            lang = re.findall('.*?\\.([a-zA-Z_]{2,7})-([a-zA-Z_]{2,7})\\.dix$', url)\n",
    "            if lang:\n",
    "                l1, l2 = lang[0][0], lang[0][1]\n",
    "                try:\n",
    "                    t = tree(url)\n",
    "                    yield t\n",
    "                except:\n",
    "                    pass\n",
    "    logging.info('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-17 18:52:17,411 | INFO : Start\n"
     ]
    }
   ],
   "source": [
    "list(save_all(user))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'dictionary' at 0x000001CCDB4114A8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree('https://raw.githubusercontent.com/apertium/apertium-urd-hin/master/apertium-urd-hin.urd-hin.dix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Word **\n",
    "\n",
    "- lemma : lemma\n",
    "- lang : language\n",
    "- pos : part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, lemma, lang, s=[]):\n",
    "        self.lemma = lemma\n",
    "        self.lang = lang\n",
    "        self.s = set(s)\n",
    "        self.slist = s\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.lang)+'_'+str(self.lemma)+'_'+str('-'.join(self.slist))\n",
    "    \n",
    "    __repr__ = __str__\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.lemma == other.lemma and self.lang == other.lang and self.s == other.s\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidix parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%time T = tree('https://raw.githubusercontent.com/apertium/apertium-bel-rus/master/apertium-bel-rus.bel-rus.dix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_word(word, lang):\n",
    "    s = word.findall('.//s')\n",
    "    s = [i.attrib['n'] for i in s]\n",
    "    return Word(word.text, lang, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_bidix (tree, l1, l2):\n",
    "    tree = tree.find('section')\n",
    "    for e in tree:\n",
    "        if 'n' in e.attrib:\n",
    "            side = e.attrib['n']\n",
    "        else:\n",
    "            side = None\n",
    "        p = e.find('p')\n",
    "        yield one_word(p.find('l'), l1), one_word(p.find('r'), l2), side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 757 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48880"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% time len(list(parse_bidix (T, 'bel','rus')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
